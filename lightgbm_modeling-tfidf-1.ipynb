{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import nltk, string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "        self.stop_words = get_stop_words('en')\n",
    "        self.stop_words.append(' ')\n",
    "        self.stop_words.append('')\n",
    "    \n",
    "    def pipeline(self, df):\n",
    "        for lang in ['description']:\n",
    "            #, 'translate_es', 'translate_fr', 'translate_de', 'translate_ja']:\n",
    "            df[lang] = df[lang].apply(lambda x: self.change_text(x))\n",
    "        return df\n",
    "\n",
    "    def change_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace('ml', 'machine learning')\n",
    "        text = text.replace('machine learning', 'machinelearning')\n",
    "        text = \"\".join([char if char not in string.punctuation else ' ' for char in text])\n",
    "        text = \" \".join([self.porter.stem(char) for char in text.split(' ') if char not in self.stop_words])\n",
    "        return text\n",
    "    \n",
    "    def vectorize_tfidf(self, df):\n",
    "        vec_tfidf = TfidfVectorizer()\n",
    "        X = vec_tfidf.fit_transform(df.description.values)\n",
    "        X = pd.DataFrame(X.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "        return X\n",
    "    \n",
    "    def vectorize_cnt(self, df):\n",
    "        vec_cnt = CountVectorizer()\n",
    "        X = vec_cnt.fit_transform(df.description.values)\n",
    "        X = pd.DataFrame(X.toarray(), columns=vec_cnt.get_feature_names())\n",
    "        return X\n",
    "\n",
    "\n",
    "class Optimize_by_Optuna:\n",
    "    def __init__(self, data, features, target_colname, target_name_2=None, _objective=None):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.target = target_colname\n",
    "        if not target_colname:\n",
    "            self.target_2 = target_colname\n",
    "        else:\n",
    "            self.target_2 = target_name_2\n",
    "        self._objective = _objective\n",
    "        \n",
    "    \n",
    "    def make_score(self, y, preds):\n",
    "        s_1=1 - metrics.accuracy_score(y, preds)\n",
    "        s_2=list(self.model.best_score['valid_1'].values())[0]\n",
    "\n",
    "        return (s_1+s_2)/2\n",
    "\n",
    "    def objective(self, trial):\n",
    "                        \n",
    "        PARAMS = {#'boosting_type': 'gbdt', 'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            \n",
    "            #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "            \n",
    "            'objective': 'tweedie','metric': 'tweedie',\n",
    "            \n",
    "            'n_estimators': 1400,\n",
    "            'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "        \n",
    "\n",
    "            'tweedie_variance_power': trial.suggest_uniform('tweedie_variance_power', 1.01, 1.8),\n",
    "\n",
    "\n",
    "            'max_bin': trial.suggest_int('max_bin', 50, 300),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.4, 0.9),\n",
    "            'subsample_freq': trial.suggest_uniform('subsample_freq', 0.4, 0.9),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.03, 0.5),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 4, 2*5),\n",
    "            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.0001, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.0001, 10.0),\n",
    "        }\n",
    "        \n",
    "        score = 0\n",
    "        k = StratifiedKFold(n_splits=5)\n",
    "        for trn, val in k.split(self.data, self.data[self.target_2]):\n",
    "            train_df = self.data.iloc[trn,:]\n",
    "            val_df = self.data.iloc[val,:]\n",
    "            train_set= lgb.Dataset(train_df[self.features],  train_df[self.target])\n",
    "            val_set = lgb.Dataset(val_df[self.features],  val_df[self.target])   \n",
    "            \n",
    "            self.model = lgb.train(\n",
    "                train_set=train_set, valid_sets=[train_set, val_set], params=PARAMS, num_boost_round=3000, \n",
    "                early_stopping_rounds=200, verbose_eval=500\n",
    "                )\n",
    "                \n",
    "            preds = self.model.predict(val_df[self.features])\n",
    "            preds = np.round(preds)\n",
    "            y = val_df[self.target]\n",
    "            s = self.make_score(y, preds)\n",
    "            score+=s/5\n",
    "            \n",
    "        return score\n",
    "\n",
    "\n",
    "class Null_Importance:\n",
    "    def __init__(self, train_X, train_y, PARAMS, y_2=None):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.y_2= y_2\n",
    "        self.PARAMS = PARAMS\n",
    "\n",
    "    def make_null_importance_df(self):\n",
    "        null_importance=pd.DataFrame()\n",
    "        null_importance['col'] = self.train_X.columns.tolist()\n",
    "        try:\n",
    "            for i in range(50):\n",
    "                tmp_null_importance=[]\n",
    "                \n",
    "                _train_y = self.train_y.apply(lambda x: random.choice([0,1]))\n",
    "                _train_y_2 = self.y_2.sample(frac=1).values\n",
    "                \n",
    "                print(f\"\"\"\n",
    "                \n",
    "                Train Null Importance   {i+1}\n",
    "                \n",
    "                \"\"\" )\n",
    "                k = StratifiedKFold(n_splits=5)\n",
    "                for trn, val in k.split(self.train_X, _train_y_2):\n",
    "                    trn_X, val_X = self.train_X.iloc[trn,:], self.train_X.iloc[val,:]\n",
    "                    trn_y, val_y = _train_y.iloc[trn].astype(int), _train_y.iloc[val].astype(int)\n",
    "                    train_set = lgb.Dataset(trn_X, trn_y)\n",
    "                    val_set = lgb.Dataset(val_X, val_y)\n",
    "\n",
    "                    model = lgb.train(params=self.PARAMS,\n",
    "                                      train_set=train_set, \n",
    "                                      valid_sets=[train_set, val_set],\n",
    "                                    num_boost_round=3000, early_stopping_rounds=200, verbose_eval=500)\n",
    "                    \n",
    "                    preds = model.predict(val_X)\n",
    "                    tmp_null_importance.append(model.feature_importance('gain'))\n",
    "                null_importance[f'null_importance_{i+1}'] = np.mean(tmp_null_importance, axis=0)\n",
    "            return null_importance\n",
    "        except:\n",
    "            return null_importance\n",
    "\n",
    "    def calu_importance(self, importance_df, null_importance_df):\n",
    "        importance_df = pd.merge(\n",
    "            importance_df, null_importance_df, on='col'\n",
    "            )\n",
    "        null_importance_col = [col for col in importance_df.columns if 'null' in col]\n",
    "        null_importance=pd.DataFrame()\n",
    "        for idx, row in importance_df.iterrows():\n",
    "            acc_v = 1e-10+row['true_importance']\n",
    "            null_v = 1+np.percentile(row[null_importance_col], 75)\n",
    "            null_importance[row['col']] = [np.log(acc_v/null_v)]\n",
    "        null_importance = null_importance.T\n",
    "        return null_importance\n",
    "\n",
    "    def all_flow(self):\n",
    "        k = StratifiedKFold(n_splits=5)\n",
    "        score=[]\n",
    "        importance=[]\n",
    "\n",
    "        importance_df=pd.DataFrame()\n",
    "        importance_df['col'] = self.train_X.columns\n",
    "        print(\"\"\"\n",
    "        \n",
    "        Train True Importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        for trn, val in k.split(self.train_X, self.y_2):\n",
    "            trn_X, val_X = self.train_X.iloc[trn,:], self.train_X.iloc[val,:]\n",
    "            trn_y, val_y = self.train_y.iloc[trn].astype(int), self.train_y.iloc[val].astype(int)\n",
    "            train_set = lgb.Dataset(trn_X, trn_y)\n",
    "            val_set = lgb.Dataset(val_X, val_y)\n",
    "            \n",
    "            PARAMS['random_state']+=1\n",
    "            model = lgb.train(params=self.PARAMS, train_set=train_set, valid_sets=[train_set, val_set],\n",
    "                            num_boost_round=3000, early_stopping_rounds=200, verbose_eval=500)\n",
    "            preds = model.predict(val_X)\n",
    "            importance.append(model.feature_importance('gain'))\n",
    "        importance_df['true_importance'] = np.mean(importance, axis=0)\n",
    "        \n",
    "        print(\"\"\"\n",
    "        \n",
    "        Train Null Importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        try:\n",
    "            null_importance_df = self.make_null_importance_df()\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\"\"\n",
    "        \n",
    "        Calulate null_null_importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        null_importance = self.calu_importance(importance_df, null_importance_df)\n",
    "        null_importance = null_importance.reset_index()\n",
    "        null_importance.columns = ['col', 'score']\n",
    "        null_importance = null_importance.sort_values('score', ascending=False)\n",
    "        return null_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/kanoumotoharu/Documents/signate_std_2020/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('../train.csv'),\n",
    "    pd.read_csv('../test.csv')],\n",
    "    axis=0,ignore_index=True)\n",
    "preprocessing = Preprocessing()\n",
    "df.description = df.description.apply(lambda x: preprocessing.change_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.vectorize_tfidf(df)\n",
    "X = pd.concat([df.jobflag, X], axis=1)\n",
    "train_df = X[X.jobflag.notnull()].reset_index(drop=True)\n",
    "test_df = X[X.jobflag.isnull()].drop(columns=['jobflag']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['abil', 'abl', 'accept', 'access', 'accord', 'account', 'accur', 'accuraci', 'achiev', 'acquisit', 'across', 'act', 'action', \n",
    "           'activ', 'ad', 'addit', 'address', 'adher', 'administr', 'advanc', 'advis', 'advisor', 'agil', 'agre', 'ai', 'algorithm', \n",
    "           'align', 'analys', 'analysi', 'analyst', 'analyt', 'analyz', 'api', 'appli', 'applic', 'approach', 'appropri', 'approv', \n",
    "           'architect', 'architectur', 'area', 'assembl', 'assess', 'assign', 'assist', 'audienc', 'autom', 'avail', 'aw', 'back',\n",
    "           'backend', 'base', 'basic', 'behavior', 'benefit', 'best', 'board', 'bug', 'build', 'busi', 'call', 'can', 'candid', 'capabl',\n",
    "           'capac', 'case', 'caus', 'challeng', 'chang', 'clearli', 'client', 'clinic', 'close', 'cloud', 'cluster', 'coach', 'code', \n",
    "           'collabor', 'collect', 'commerci', 'commiss', 'commun', 'compani', 'complet', 'complex', 'complianc', 'compon', 'comput', \n",
    "           'concept', 'conduct', 'confer', 'configur', 'connect', 'consist', 'construct', 'consult', 'content', 'continu', 'contract',\n",
    "           'contribut', 'control', 'coordin', 'core', 'corpor', 'correct', 'cost', 'creat', 'creation', 'creativ', 'critic', 'cross', \n",
    "           'cultur', 'current', 'custom', 'cycl', 'daili', 'dashboard', 'data', 'databas', 'dataset', 'date', 'deadlin', 'debug', 'decis',\n",
    "           'deep', 'defect', 'defin', 'definit', 'deliv', 'deliver', 'deliveri', 'demand', 'demonstr', 'depart', 'depend', 'deploy', 'depth',\n",
    "           'deriv', 'design', 'desir', 'detail', 'detect', 'determin', 'develop', 'devic', 'devop', 'differ', 'digit', 'direct', 'disciplin',\n",
    "           'discoveri', 'discuss', 'distribut', 'divers', 'document', 'domain', 'draw', 'drive', 'duti', 'dynam', 'edg', 'educ', 'effect',\n",
    "           'effici', 'effort', 'electron', 'email', 'embed', 'employe', 'enabl', 'end', 'engag', 'engin', 'enhanc', 'ensur', 'enterpris',\n",
    "           'environ', 'equip', 'erp', 'escal', 'establish', 'estim', 'etc', 'evalu', 'event', 'excel', 'execut', 'exist', 'expand', 'experi',\n",
    "           'expert', 'expertis', 'explain', 'explor', 'exploratori', 'extern', 'extract', 'face', 'facilit', 'failur', 'featur', 'feder', \n",
    "           'field', 'find', 'fix', 'flow', 'focu', 'follow', 'form', 'formul', 'framework', 'front', 'full', 'function', 'futur', 'gain',\n",
    "           'gap', 'gather', 'gener', 'global', 'go', 'goal', 'good', 'govern', 'group', 'grow', 'growth', 'guid', 'guidanc', 'hand', \n",
    "           'hardwar', 'healthcar', 'help', 'high', 'highli', 'hoc', 'idea', 'identifi', 'impact', 'implement', 'improv', 'incid', 'includ',\n",
    "           'increas', 'independ', 'individu', 'industri', 'influenc', 'inform', 'infrastructur', 'initi', 'innov', 'input', 'insight',\n",
    "           'inspect', 'instal', 'integr', 'intellig', 'interact', 'interfac', 'intern', 'interpret', 'investig', 'issu', 'iter', 'java',\n",
    "           'job', 'junior', 'keep', 'key', 'knowledg', 'languag', 'larg', 'latest', 'lead', 'leader', 'leadership', 'learn', 'level', \n",
    "           'leverag', 'librari', 'life', 'like', 'limit', 'linux', 'log', 'logic', 'machin', 'machinelearn', 'maintain', 'mainten', \n",
    "           'make', 'manag', 'manner', 'manufactur', 'map', 'market', 'materi', 'matter', 'may', 'measur', 'mechan', 'medic', 'meet',\n",
    "           'member', 'mentor', 'met', 'method', 'methodolog', 'metric', 'microsoft', 'migrat', 'mission', 'mobil', 'model', 'moder',\n",
    "           'modifi', 'modul', 'monitor', 'multi', 'multipl', 'must', 'necessari', 'need', 'net', 'network', 'new', 'next', 'non', 'novel',\n",
    "           'object', 'obtain', 'ongo', 'open', 'oper', 'opportun', 'optim', 'order', 'organ', 'organiz', 'orient', 'outcom', 'outsid',\n",
    "           'overal', 'overse', 'part', 'parti', 'particip', 'partner', 'partnership', 'pattern', 'payrol', 'peer', 'perform', 'person',\n",
    "           'personnel', 'pipelin', 'plan', 'platform', 'point', 'polici', 'posit', 'post', 'potenti', 'practic', 'pre', 'predict', 'prepar', \n",
    "           'present', 'price', 'principl', 'prior', 'priorit', 'proactiv', 'problem', 'procedur', 'process', 'produc', 'product', \n",
    "           'profession', 'program', 'progress', 'project', 'promot', 'proof', 'propos', 'prospect', 'protocol', 'prototyp','provid', \n",
    "           'purpos', 'python', 'qa', 'qualifi', 'qualiti', 'queri', 'question', 'quickli', 'real', 'recommend', 'referr', 'refin', 'regard',\n",
    "           'region', 'regul', 'regular', 'regulatori', 'relat', 'relationship', 'releas', 'relev', 'reliabl', 'report','repres', 'request',\n",
    "           'requir', 'research', 'resid', 'resolut', 'resolv', 'resourc', 'respons', 'result', 'retail', 'review', 'rigor', 'risk', 'roadmap',\n",
    "           'role', 'root', 'rule', 'run', 'safeti', 'sale', 'scalabl', 'scale', 'schedul', 'scienc', 'scientist', 'scope', 'script', 'scrum',\n",
    "           'secur', 'segment', 'select', 'self', 'sell', 'senior', 'serv', 'server', 'servic', 'set', 'share', 'show', 'simul', 'site',\n",
    "           'skill', 'small', 'softwar', 'solut', 'solv', 'sourc', 'specif', 'sql', 'stack', 'staff', 'stakehold', 'standard', 'state',\n",
    "           'statist', 'statu', 'stay', 'store', 'stori', 'strateg', 'strategi', 'stream', 'strong', 'structur', 'studi', 'subject', \n",
    "           'success', 'suggest', 'supplier', 'support', 'system', 'take', 'target', 'task', 'team', 'technic', 'techniqu', 'technolog', \n",
    "           'term','test', 'think', 'thought', 'throughout', 'time', 'timelin', 'tool', 'top', 'track', 'train', 'transform', 'translat',\n",
    "           'travel', 'trend', 'troubleshoot', 'tune', 'understand', 'unit', 'updat', 'upgrad', 'use', 'user', 'util', 'valid',\n",
    "           'valu', 'variou', 'vehicl', 'vendor', 'verif', 'verifi', 'version', 'via', 'vision', 'visual', 'way',\n",
    "           'web', 'well', 'wide', 'will', 'window', 'within', 'work', 'workflow','write']\n",
    "\n",
    "PARAMS_1={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "   'tweedie_variance_power': 1.349969119190657, 'max_bin': 212, 'subsample': 0.5774043241504451, 'subsample_freq': 0.7045972939301558, \n",
    "    'learning_rate': 0.16528226095247364, 'num_leaves': 4, 'feature_fraction': 0.9964784224971625,\n",
    "    'bagging_freq': 6, 'min_child_samples': 23, 'lambda_l1': 0.016924825494747078, 'lambda_l2': 0.0008031532180312293\n",
    "}\n",
    "\n",
    "\n",
    "PARAMS_2={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'tweedie_variance_power': 1.3014991003823067, 'max_bin': 134, 'subsample': 0.8990859498726816, 'subsample_freq': 0.5274951186330312,\n",
    "    'learning_rate': 0.3937162652059595, 'num_leaves': 5, 'feature_fraction': 0.8861294810479933, 'bagging_freq': 5,\n",
    "    'min_child_samples': 28, 'lambda_l1': 6.037171725930821, 'lambda_l2': 0.0025254105473444784\n",
    "}\n",
    "\n",
    "PARAMS_3={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    #'objective': 'tweedie','metric': 'tweedie',\n",
    "     \n",
    "    'objective': 'xentropy','metric': 'xentropy',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'max_bin': 50, 'subsample': 0.8509082362331666, 'subsample_freq': 0.6958806976511948, 'learning_rate': 0.09406169926162017,\n",
    "    'num_leaves': 7, 'feature_fraction': 0.7562554580497556, 'bagging_freq': 4, 'min_child_samples': 5, 'lambda_l1': 0.00021420978217365439,\n",
    "    'lambda_l2': 0.011867471326820044\n",
    "}\n",
    "\n",
    "PARAMS_4={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'tweedie_variance_power': 1.3572492826220748, 'max_bin': 169, 'subsample': 0.6874225607452877, 'subsample_freq': 0.5369168449326642,\n",
    "    'learning_rate': 0.0353671206084155, 'num_leaves': 8, 'feature_fraction': 0.9508830019260512, \n",
    "    'bagging_freq': 2, 'min_child_samples': 63, 'lambda_l1': 8.281467382972142, 'lambda_l2': 0.1428656656583413\n",
    "}\n",
    "\n",
    "param_list = [PARAMS_1, PARAMS_2, PARAMS_3, PARAMS_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[feature+['jobflag']]\n",
    "test_df = test_df[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>web</th>\n",
       "      <th>well</th>\n",
       "      <th>wide</th>\n",
       "      <th>will</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215403</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit   ...     web  well  wide  will  window  within  work  workflow  \\\n",
       "0       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "1       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "2       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "3       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "4       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "\n",
       "      write  jobflag  \n",
       "0  0.215403      2.0  \n",
       "1  0.000000      3.0  \n",
       "2  0.000000      4.0  \n",
       "3  0.000000      1.0  \n",
       "4  0.000000      4.0  \n",
       "\n",
       "[5 rows x 539 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>well</th>\n",
       "      <th>wide</th>\n",
       "      <th>will</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit  ...    way  web  well  wide  will  window  within      work  \\\n",
       "0       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.544329   \n",
       "1       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "2       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "3       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "4       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "\n",
       "   workflow  write  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "\n",
       "[5 rows x 538 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_offdf(train_df, feature, params_list):\n",
    "    k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    \n",
    "    y_1 = train_df.jobflag.apply(lambda x: 1 if x==1 else 0)\n",
    "    y_2 = train_df.jobflag.apply(lambda x: 1 if x==2 else 0)\n",
    "    y_3 = train_df.jobflag.apply(lambda x: 1 if x==3 else 0)\n",
    "    y_4 = train_df.jobflag.apply(lambda x: 1 if x==4 else 0)\n",
    "    \n",
    "    off_df = []\n",
    "    \n",
    "    for trn, val in k.split(train_df, train_df.jobflag):\n",
    "        train_X, val_X = train_df.iloc[trn,:][feature], train_df.iloc[val,:][feature]\n",
    "        tmp_off_df = train_df.iloc[val,:]\n",
    "        c=1\n",
    "        for y, param in zip([y_1, y_2, y_3, y_4], params_list):\n",
    "            tmp_off_df[f'preds_{c}']=0\n",
    "            for _ in range(5):\n",
    "                train_y, val_y = y.iloc[trn], y.iloc[val]\n",
    "                train_set= lgb.Dataset(train_X,  train_y)\n",
    "                val_set = lgb.Dataset(val_X,  val_y)   \n",
    "\n",
    "                model = lgb.train(\n",
    "                    train_set=train_set, valid_sets=[train_set, val_set], params=param, num_boost_round=3000, \n",
    "                    early_stopping_rounds=200, verbose_eval=500\n",
    "                )\n",
    "                tmp_off_df[f'preds_{c}'] += model.predict(val_X)/5\n",
    "                param['random_state']+=1\n",
    "            c+=1\n",
    "            \n",
    "        off_df.append(tmp_off_df)\n",
    "    off_df = pd.concat(off_df, axis=0)\n",
    "    return off_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's tweedie: 1.4199\tvalid_1's tweedie: 1.4728\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's tweedie: 1.43633\tvalid_1's tweedie: 1.45725\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's tweedie: 1.3984\tvalid_1's tweedie: 1.459\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's tweedie: 1.42015\tvalid_1's tweedie: 1.46871\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's tweedie: 1.43688\tvalid_1's tweedie: 1.46106\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's tweedie: 0.966042\tvalid_1's tweedie: 1.01967\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's tweedie: 0.957793\tvalid_1's tweedie: 1.01925\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's tweedie: 0.948541\tvalid_1's tweedie: 1.01419\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's tweedie: 0.920607\tvalid_1's tweedie: 1.01227\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's tweedie: 0.941303\tvalid_1's tweedie: 1.01529\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\ttraining's cross_entropy: 0.29288\tvalid_1's cross_entropy: 0.498069\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-fa03f9465c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moff_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_offdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-5e142d671271>\u001b[0m in \u001b[0;36mmake_offdf\u001b[0;34m(train_df, feature, params_list)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 model = lgb.train(\n\u001b[1;32m     23\u001b[0m                     \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 )\n\u001b[1;32m     26\u001b[0m                 \u001b[0mtmp_off_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'preds_{c}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \"\"\"\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2639\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2641\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2642\u001b[0m             \u001b[0mtmp_out_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2643\u001b[0m             _safe_call(_LIB.LGBM_BoosterGetEval(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "off_df = make_offdf(train_df, feature, param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190896</td>\n",
       "      <td>-0.489229</td>\n",
       "      <td>-0.259152</td>\n",
       "      <td>0.534806</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>-0.451053</td>\n",
       "      <td>-0.148197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.190896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.345280</td>\n",
       "      <td>-0.182900</td>\n",
       "      <td>0.115787</td>\n",
       "      <td>0.375814</td>\n",
       "      <td>-0.213224</td>\n",
       "      <td>-0.175463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>-0.489229</td>\n",
       "      <td>-0.345280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.468737</td>\n",
       "      <td>-0.406915</td>\n",
       "      <td>-0.232608</td>\n",
       "      <td>0.589403</td>\n",
       "      <td>-0.109982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>-0.259152</td>\n",
       "      <td>-0.182900</td>\n",
       "      <td>-0.468737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.133528</td>\n",
       "      <td>-0.180366</td>\n",
       "      <td>-0.101555</td>\n",
       "      <td>0.431663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_1</th>\n",
       "      <td>0.534806</td>\n",
       "      <td>0.115787</td>\n",
       "      <td>-0.406915</td>\n",
       "      <td>-0.133528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301768</td>\n",
       "      <td>-0.671779</td>\n",
       "      <td>-0.229457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_2</th>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.375814</td>\n",
       "      <td>-0.232608</td>\n",
       "      <td>-0.180366</td>\n",
       "      <td>0.301768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.397468</td>\n",
       "      <td>-0.322559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_3</th>\n",
       "      <td>-0.451053</td>\n",
       "      <td>-0.213224</td>\n",
       "      <td>0.589403</td>\n",
       "      <td>-0.101555</td>\n",
       "      <td>-0.671779</td>\n",
       "      <td>-0.397468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.130546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_4</th>\n",
       "      <td>-0.148197</td>\n",
       "      <td>-0.175463</td>\n",
       "      <td>-0.109982</td>\n",
       "      <td>0.431663</td>\n",
       "      <td>-0.229457</td>\n",
       "      <td>-0.322559</td>\n",
       "      <td>-0.130546</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1.0       2.0       3.0       4.0   preds_1   preds_2   preds_3  \\\n",
       "1.0      1.000000 -0.190896 -0.489229 -0.259152  0.534806  0.162500 -0.451053   \n",
       "2.0     -0.190896  1.000000 -0.345280 -0.182900  0.115787  0.375814 -0.213224   \n",
       "3.0     -0.489229 -0.345280  1.000000 -0.468737 -0.406915 -0.232608  0.589403   \n",
       "4.0     -0.259152 -0.182900 -0.468737  1.000000 -0.133528 -0.180366 -0.101555   \n",
       "preds_1  0.534806  0.115787 -0.406915 -0.133528  1.000000  0.301768 -0.671779   \n",
       "preds_2  0.162500  0.375814 -0.232608 -0.180366  0.301768  1.000000 -0.397468   \n",
       "preds_3 -0.451053 -0.213224  0.589403 -0.101555 -0.671779 -0.397468  1.000000   \n",
       "preds_4 -0.148197 -0.175463 -0.109982  0.431663 -0.229457 -0.322559 -0.130546   \n",
       "\n",
       "          preds_4  \n",
       "1.0     -0.148197  \n",
       "2.0     -0.175463  \n",
       "3.0     -0.109982  \n",
       "4.0      0.431663  \n",
       "preds_1 -0.229457  \n",
       "preds_2 -0.322559  \n",
       "preds_3 -0.130546  \n",
       "preds_4  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    pd.get_dummies(off_df.jobflag)[[1,2,3,4]],\n",
    "    off_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = off_df.jobflag.value_counts().min()\n",
    "min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123461</td>\n",
       "      <td>0.063152</td>\n",
       "      <td>0.741710</td>\n",
       "      <td>0.319956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173057</td>\n",
       "      <td>0.222903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.022526</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.338652</td>\n",
       "      <td>0.388339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.234244</td>\n",
       "      <td>0.274589</td>\n",
       "      <td>0.142482</td>\n",
       "      <td>0.035066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.099146</td>\n",
       "      <td>0.806713</td>\n",
       "      <td>0.029701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.144609</td>\n",
       "      <td>0.146858</td>\n",
       "      <td>0.863224</td>\n",
       "      <td>0.186783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.057403</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.575559</td>\n",
       "      <td>0.123173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.121605</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.761970</td>\n",
       "      <td>0.214502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.177861</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.011751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.065608</td>\n",
       "      <td>0.700009</td>\n",
       "      <td>0.192180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623325</td>\n",
       "      <td>0.099781</td>\n",
       "      <td>0.079780</td>\n",
       "      <td>0.091348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "447    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2104   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "474    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2792   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "830    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1931   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "621    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1598   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2068   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "46     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "      acquisit    ...     window    within      work  workflow  write  \\\n",
       "447   0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "2104  0.000000    ...        0.0  0.173057  0.222903       0.0    0.0   \n",
       "474   0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "2792  0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "830   0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "1931  0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "621   0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "1598  0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "2068  0.236698    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "46    0.000000    ...        0.0  0.000000  0.000000       0.0    0.0   \n",
       "\n",
       "      jobflag   preds_1   preds_2   preds_3   preds_4  \n",
       "447       1.0  0.123461  0.063152  0.741710  0.319956  \n",
       "2104      4.0  0.022526  0.017879  0.338652  0.388339  \n",
       "474       2.0  0.234244  0.274589  0.142482  0.035066  \n",
       "2792      3.0  0.014103  0.099146  0.806713  0.029701  \n",
       "830       3.0  0.144609  0.146858  0.863224  0.186783  \n",
       "1931      3.0  0.057403  0.042683  0.575559  0.123173  \n",
       "621       4.0  0.121605  0.079146  0.761970  0.214502  \n",
       "1598      2.0  0.177861  0.611637  0.082809  0.011751  \n",
       "2068      3.0  0.231034  0.065608  0.700009  0.192180  \n",
       "46        1.0  0.623325  0.099781  0.079780  0.091348  \n",
       "\n",
       "[10 rows x 543 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_df.sample(n=10, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94843d43acf443c181cbf86d6f082330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c38208ae9c4c4f82d9e36e47d413eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a564e4759b724089aa1a4a4fe9fcea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b851822f944d508314ac2f6318f34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83728f561dc4ef5acafd675adbfebd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "off_df_2=[]\n",
    "for trn, val in k.split(train_df, train_df.jobflag):\n",
    "    trn_df = off_df.iloc[trn,:]\n",
    "    val_df  =  off_df.iloc[val,:]\n",
    "    \n",
    "    min_value = trn_df.jobflag.value_counts().min()\n",
    "    \n",
    "    preds = np.zeros(shape=(len(val_df),4))\n",
    "    \n",
    "    for i in tqdm(range(100)):\n",
    "        tmp_trn_df = pd.concat(\n",
    "        [trn_df[trn_df.jobflag==1].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==2].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==3].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==4].sample(n=min_value, random_state=i)], axis=0).reset_index(drop=True)\n",
    "        tmp_trn_X = tmp_trn_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "        tmp_trn_y = tmp_trn_df['jobflag']\n",
    "        \n",
    "        \n",
    "        for penalty  in [ 'l2']:\n",
    "            for m in range(10):\n",
    "                logit = LogisticRegression(penalty=penalty, random_state=m)\n",
    "                logit.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #ridge_cls = RidgeClassifier()\n",
    "                    #ridge_cls.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #kncls = KNeighborsClassifier(n_neighbors=4)\n",
    "                    #kncls.fit(tmp_trn_X, tmp_trn_y)\n",
    "                preds += logit.predict_proba(val_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])\n",
    "        \n",
    "    val_df[f'preds'] = np.argmax(preds, axis=1)+1\n",
    "    off_df_2.append(val_df)\n",
    "off_df_2 = pd.concat(off_df_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5745794965996607\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344</td>\n",
       "      <td>132</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>168</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>93</td>\n",
       "      <td>927</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>135</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  344  132   68   80\n",
       "1   72  168   67   41\n",
       "2   70   93  927  286\n",
       "3   55   21  135  372"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics.f1_score(off_df_2.jobflag, off_df_2.preds, average='macro'))\n",
    "plt.figure(figsize=(10,10))\n",
    "cnfn_matrix = pd.DataFrame(metrics.confusion_matrix(off_df_2.jobflag, off_df_2.preds))\n",
    "#cnfn_matrix.index = \n",
    "sns.heatmap(cnfn_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "cnfn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215403</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>0.080122</td>\n",
       "      <td>0.751037</td>\n",
       "      <td>0.039722</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.143237</td>\n",
       "      <td>0.109266</td>\n",
       "      <td>0.547021</td>\n",
       "      <td>0.163301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181536</td>\n",
       "      <td>0.079719</td>\n",
       "      <td>0.254609</td>\n",
       "      <td>0.238883</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.038996</td>\n",
       "      <td>0.631684</td>\n",
       "      <td>0.365082</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.485747</td>\n",
       "      <td>0.058523</td>\n",
       "      <td>0.153773</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>0.163893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.045960</td>\n",
       "      <td>0.940351</td>\n",
       "      <td>0.060085</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.139157</td>\n",
       "      <td>0.069632</td>\n",
       "      <td>0.523132</td>\n",
       "      <td>0.238104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.380442</td>\n",
       "      <td>0.546535</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>0.021093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.458717</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>0.090542</td>\n",
       "      <td>0.148519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.083187</td>\n",
       "      <td>0.051411</td>\n",
       "      <td>0.315195</td>\n",
       "      <td>0.276268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.298118</td>\n",
       "      <td>0.048186</td>\n",
       "      <td>0.210028</td>\n",
       "      <td>0.217319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.134225</td>\n",
       "      <td>0.172296</td>\n",
       "      <td>0.409851</td>\n",
       "      <td>0.110272</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.139157</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.562260</td>\n",
       "      <td>0.161395</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.182678</td>\n",
       "      <td>0.048435</td>\n",
       "      <td>0.250606</td>\n",
       "      <td>0.417194</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.076574</td>\n",
       "      <td>0.255422</td>\n",
       "      <td>0.090830</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.777140</td>\n",
       "      <td>0.035411</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.109620</td>\n",
       "      <td>0.055581</td>\n",
       "      <td>0.286459</td>\n",
       "      <td>0.647473</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169096</td>\n",
       "      <td>0.497547</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.082408</td>\n",
       "      <td>0.076394</td>\n",
       "      <td>0.705161</td>\n",
       "      <td>0.088520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.034558</td>\n",
       "      <td>0.030074</td>\n",
       "      <td>0.937148</td>\n",
       "      <td>0.018439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.168166</td>\n",
       "      <td>0.043841</td>\n",
       "      <td>0.077927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.103801</td>\n",
       "      <td>0.056528</td>\n",
       "      <td>0.843497</td>\n",
       "      <td>0.095388</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.139157</td>\n",
       "      <td>0.069632</td>\n",
       "      <td>0.512136</td>\n",
       "      <td>0.217735</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.089056</td>\n",
       "      <td>0.028834</td>\n",
       "      <td>0.651086</td>\n",
       "      <td>0.483461</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.139157</td>\n",
       "      <td>0.060136</td>\n",
       "      <td>0.255642</td>\n",
       "      <td>0.188873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.112975</td>\n",
       "      <td>0.072283</td>\n",
       "      <td>0.733658</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.501945</td>\n",
       "      <td>0.163092</td>\n",
       "      <td>0.141659</td>\n",
       "      <td>0.109897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.335947</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.190462</td>\n",
       "      <td>0.262002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.043249</td>\n",
       "      <td>0.069632</td>\n",
       "      <td>0.792874</td>\n",
       "      <td>0.181849</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.126433</td>\n",
       "      <td>0.067814</td>\n",
       "      <td>0.335273</td>\n",
       "      <td>0.281194</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.088659</td>\n",
       "      <td>0.056705</td>\n",
       "      <td>0.456786</td>\n",
       "      <td>0.342479</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.352270</td>\n",
       "      <td>0.191786</td>\n",
       "      <td>0.441123</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.699149</td>\n",
       "      <td>0.292678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290782</td>\n",
       "      <td>0.508689</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>0.041345</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.375169</td>\n",
       "      <td>1.091067</td>\n",
       "      <td>0.076282</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.849259</td>\n",
       "      <td>0.083329</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.151109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.218427</td>\n",
       "      <td>0.042932</td>\n",
       "      <td>0.510765</td>\n",
       "      <td>0.219641</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>0.685730</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.617010</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>0.030046</td>\n",
       "      <td>0.148542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783233</td>\n",
       "      <td>0.056889</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>0.179765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.314702</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>0.155451</td>\n",
       "      <td>0.172916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707787</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.043471</td>\n",
       "      <td>0.090367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162181</td>\n",
       "      <td>0.067814</td>\n",
       "      <td>0.517765</td>\n",
       "      <td>0.254110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.227779</td>\n",
       "      <td>0.032094</td>\n",
       "      <td>0.366125</td>\n",
       "      <td>0.669851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.754430</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.162181</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.781885</td>\n",
       "      <td>0.347932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.163322</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>0.258148</td>\n",
       "      <td>0.246487</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.642466</td>\n",
       "      <td>0.470301</td>\n",
       "      <td>0.029729</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.073182</td>\n",
       "      <td>0.124154</td>\n",
       "      <td>0.867315</td>\n",
       "      <td>0.136010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.203242</td>\n",
       "      <td>0.278423</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.162181</td>\n",
       "      <td>0.067814</td>\n",
       "      <td>0.226071</td>\n",
       "      <td>0.254110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.628190</td>\n",
       "      <td>0.645274</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.119214</td>\n",
       "      <td>0.067814</td>\n",
       "      <td>0.734405</td>\n",
       "      <td>0.131499</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.056435</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>0.404357</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.130077</td>\n",
       "      <td>0.141034</td>\n",
       "      <td>0.429187</td>\n",
       "      <td>0.125642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.556656</td>\n",
       "      <td>0.050447</td>\n",
       "      <td>0.222125</td>\n",
       "      <td>0.186830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509147</td>\n",
       "      <td>0.106268</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.288858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.132150</td>\n",
       "      <td>0.055743</td>\n",
       "      <td>0.177935</td>\n",
       "      <td>0.267588</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.618297</td>\n",
       "      <td>0.154847</td>\n",
       "      <td>0.163707</td>\n",
       "      <td>0.056775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2931 rows × 544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abil  abl  accept  access  accord  account  accur  accuraci    achiev  \\\n",
       "0      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "1      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "3      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "4      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "5      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.292116   \n",
       "6      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "7      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "8      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "9      0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "10     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "11     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "12     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "13     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "14     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "15     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "16     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "17     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "18     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "19     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "20     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "21     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "22     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "23     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "24     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "25     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "26     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "27     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "28     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "29     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "...    ...  ...     ...     ...     ...      ...    ...       ...       ...   \n",
       "2901   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2902   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2903   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2904   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2905   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2906   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2907   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2908   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2909   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2910   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2911   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2912   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2913   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2914   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2915   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2916   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2917   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2918   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2919   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2920   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2921   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2922   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2923   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2924   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2925   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2926   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2927   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2928   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2929   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "2930   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0  0.000000   \n",
       "\n",
       "      acquisit  ...      within      work  workflow     write  jobflag  \\\n",
       "0          0.0  ...    0.000000  0.000000       0.0  0.215403      2.0   \n",
       "1          0.0  ...    0.000000  0.210919       0.0  0.000000      3.0   \n",
       "2          0.0  ...    0.000000  0.252359       0.0  0.000000      1.0   \n",
       "3          0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "4          0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "5          0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "6          0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "7          0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "8          0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "9          0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "10         0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "11         0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "12         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "13         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "14         0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "15         0.0  ...    0.347748  0.000000       0.0  0.000000      3.0   \n",
       "16         0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "17         0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "18         0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "19         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "20         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "21         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "22         0.0  ...    0.000000  0.136328       0.0  0.000000      3.0   \n",
       "23         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "24         0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "25         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "26         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "27         0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "28         0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "29         0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "...        ...  ...         ...       ...       ...       ...      ...   \n",
       "2901       0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "2902       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2903       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2904       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2905       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2906       0.0  ...    0.000000  0.185620       0.0  0.000000      2.0   \n",
       "2907       0.0  ...    0.000000  0.130724       0.0  0.000000      1.0   \n",
       "2908       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2909       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2910       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2911       0.0  ...    0.000000  0.145035       0.0  0.000000      1.0   \n",
       "2912       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2913       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2914       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2915       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2916       0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "2917       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2918       0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "2919       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2920       0.0  ...    0.000000  0.201446       0.0  0.000000      3.0   \n",
       "2921       0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "2922       0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "2923       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2924       0.0  ...    0.000000  0.000000       0.0  0.000000      3.0   \n",
       "2925       0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "2926       0.0  ...    0.000000  0.173982       0.0  0.000000      3.0   \n",
       "2927       0.0  ...    0.000000  0.000000       0.0  0.000000      4.0   \n",
       "2928       0.0  ...    0.000000  0.169677       0.0  0.000000      1.0   \n",
       "2929       0.0  ...    0.000000  0.000000       0.0  0.000000      1.0   \n",
       "2930       0.0  ...    0.000000  0.000000       0.0  0.000000      2.0   \n",
       "\n",
       "       preds_1   preds_2   preds_3   preds_4  preds  \n",
       "0     0.115409  0.080122  0.751037  0.039722      3  \n",
       "1     0.143237  0.109266  0.547021  0.163301      3  \n",
       "2     0.181536  0.079719  0.254609  0.238883      4  \n",
       "3     0.032362  0.038996  0.631684  0.365082      4  \n",
       "4     0.485747  0.058523  0.153773  0.028618      1  \n",
       "5     0.150100  0.159302  0.169095  0.163893      2  \n",
       "6     0.046986  0.045960  0.940351  0.060085      3  \n",
       "7     0.139157  0.069632  0.523132  0.238104      4  \n",
       "8     0.380442  0.546535  0.031757  0.021093      2  \n",
       "9     0.458717  0.064607  0.090542  0.148519      1  \n",
       "10    0.083187  0.051411  0.315195  0.276268      4  \n",
       "11    0.298118  0.048186  0.210028  0.217319      1  \n",
       "12    0.134225  0.172296  0.409851  0.110272      2  \n",
       "13    0.139157  0.071554  0.562260  0.161395      3  \n",
       "14    0.182678  0.048435  0.250606  0.417194      4  \n",
       "15    0.063396  0.076574  0.255422  0.090830      2  \n",
       "16    0.025396  0.117095  0.777140  0.035411      3  \n",
       "17    0.109620  0.055581  0.286459  0.647473      4  \n",
       "18    0.169096  0.497547  0.043710  0.007275      2  \n",
       "19    0.082408  0.076394  0.705161  0.088520      3  \n",
       "20    0.034558  0.030074  0.937148  0.018439      3  \n",
       "21    0.544883  0.168166  0.043841  0.077927      1  \n",
       "22    0.103801  0.056528  0.843497  0.095388      3  \n",
       "23    0.139157  0.069632  0.512136  0.217735      3  \n",
       "24    0.089056  0.028834  0.651086  0.483461      4  \n",
       "25    0.139157  0.060136  0.255642  0.188873      4  \n",
       "26    0.112975  0.072283  0.733658  0.002892      3  \n",
       "27    0.501945  0.163092  0.141659  0.109897      1  \n",
       "28    0.335947  0.059500  0.190462  0.262002      1  \n",
       "29    0.043249  0.069632  0.792874  0.181849      3  \n",
       "...        ...       ...       ...       ...    ...  \n",
       "2901  0.126433  0.067814  0.335273  0.281194      4  \n",
       "2902  0.088659  0.056705  0.456786  0.342479      4  \n",
       "2903  0.352270  0.191786  0.441123  0.023213      2  \n",
       "2904  0.026440  0.031774  0.699149  0.292678      3  \n",
       "2905  0.290782  0.508689  0.043025  0.041345      2  \n",
       "2906  0.375169  1.091067  0.076282  0.005169      2  \n",
       "2907  0.849259  0.083329  0.023988  0.151109      1  \n",
       "2908  0.218427  0.042932  0.510765  0.219641      4  \n",
       "2909  0.013507  0.041325  0.685730  0.022876      3  \n",
       "2910  0.617010  0.080873  0.030046  0.148542      1  \n",
       "2911  0.783233  0.056889  0.044045  0.179765      1  \n",
       "2912  0.314702  0.032045  0.155451  0.172916      1  \n",
       "2913  0.707787  0.105593  0.043471  0.090367      1  \n",
       "2914  0.162181  0.067814  0.517765  0.254110      4  \n",
       "2915  0.227779  0.032094  0.366125  0.669851      4  \n",
       "2916  0.124390  0.026014  0.754430  0.032376      3  \n",
       "2917  0.162181  0.062807  0.781885  0.347932      3  \n",
       "2918  0.163322  0.030433  0.258148  0.246487      4  \n",
       "2919  0.642466  0.470301  0.029729  0.017545      1  \n",
       "2920  0.073182  0.124154  0.867315  0.136010      3  \n",
       "2921  0.200288  0.203242  0.278423  0.003651      2  \n",
       "2922  0.162181  0.067814  0.226071  0.254110      4  \n",
       "2923  0.036702  0.048693  0.628190  0.645274      4  \n",
       "2924  0.119214  0.067814  0.734405  0.131499      3  \n",
       "2925  0.056435  0.051594  0.689157  0.404357      4  \n",
       "2926  0.130077  0.141034  0.429187  0.125642      2  \n",
       "2927  0.556656  0.050447  0.222125  0.186830      1  \n",
       "2928  0.509147  0.106268  0.024717  0.288858      1  \n",
       "2929  0.132150  0.055743  0.177935  0.267588      4  \n",
       "2930  0.618297  0.154847  0.163707  0.056775      1  \n",
       "\n",
       "[2931 rows x 544 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1f9ff8e4f04b03a37b9ed6f920690c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfd55a64f5b4c8d9ca98b08abc30c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0361e31f5aed4e62b17da873c44d75e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6459bcb3f66443269838b320f7b31457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04b48644f6545708bc6b989e8606715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "off_df_2=[]\n",
    "for trn, val in k.split(train_df, train_df.jobflag):\n",
    "    trn_df = off_df.iloc[trn,:]\n",
    "    val_df  =  off_df.iloc[val,:]\n",
    "    \n",
    "    min_value = trn_df.jobflag.value_counts().min()\n",
    "    \n",
    "    preds = np.zeros(shape=(len(val_df),4))\n",
    "    \n",
    "    for i in tqdm(range(20)):\n",
    "        tmp_trn_df = pd.concat(\n",
    "        [trn_df[trn_df.jobflag==1].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==2].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==3].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==4].sample(n=min_value, random_state=i)], axis=0).reset_index(drop=True)\n",
    "        tmp_trn_X = tmp_trn_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "        tmp_trn_y = tmp_trn_df['jobflag']\n",
    "        \n",
    "        \n",
    "        for penalty  in [ 'l2']:\n",
    "            for m in range(3):\n",
    "                logit = LogisticRegression(penalty=penalty, random_state=m)\n",
    "                logit.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #ridge_cls = RidgeClassifier()\n",
    "                    #ridge_cls.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #kncls = KNeighborsClassifier(n_neighbors=4)\n",
    "                    #kncls.fit(tmp_trn_X, tmp_trn_y)\n",
    "                preds += logit.predict_proba(val_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])\n",
    "        \n",
    "    val_df[f'preds'] = np.argmax(preds, axis=1)+1\n",
    "    off_df_2.append(val_df)\n",
    "off_df_2 = pd.concat(off_df_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5745794965996607\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344</td>\n",
       "      <td>132</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>168</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>93</td>\n",
       "      <td>927</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>135</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  344  132   68   80\n",
       "1   72  168   67   41\n",
       "2   70   93  927  286\n",
       "3   55   21  135  372"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics.f1_score(off_df_2.jobflag, off_df_2.preds, average='macro'))\n",
    "plt.figure(figsize=(10,10))\n",
    "cnfn_matrix = pd.DataFrame(metrics.confusion_matrix(off_df_2.jobflag, off_df_2.preds))\n",
    "#cnfn_matrix.index = \n",
    "sns.heatmap(cnfn_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "cnfn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e6b426f86f4aa0bb87b46e0b52e568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ff55ec13c500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mgpcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mgpcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_trn_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_trn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mpreds_gpcls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgpcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m'preds_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preds_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preds_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preds_4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                  % self.multi_class)\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 239\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_sr_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_posterior_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_temporaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36m_posterior_mode\u001b[0;34m(self, K, return_temporaries)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;31m# Line 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mW_sr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mW_sr_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_sr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mW_sr_K\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW_sr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "off_df_2=[]\n",
    "for trn, val in k.split(train_df, train_df.jobflag):\n",
    "    trn_df = off_df.iloc[trn,:]\n",
    "    val_df  =  off_df.iloc[val,:]\n",
    "    \n",
    "    min_value = trn_df.jobflag.value_counts().min()\n",
    "    \n",
    "    preds_logit = np.zeros(shape=(len(val_df),4))\n",
    "    preds_gpcls = np.zeros(shape=(len(val_df),4))\n",
    "    preds_gnb = np.zeros(shape=(len(val_df),4))\n",
    "    \n",
    "    for i in tqdm(range(20)):\n",
    "        tmp_trn_df = pd.concat(\n",
    "        [trn_df[trn_df.jobflag==1].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==2].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==3].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==4].sample(n=min_value, random_state=i)], axis=0).reset_index(drop=True)\n",
    "        tmp_trn_X = tmp_trn_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "        tmp_trn_y = tmp_trn_df['jobflag']\n",
    "        \n",
    "        for m in range(3):\n",
    "            logit = LogisticRegression(random_state=m)\n",
    "            logit.fit(tmp_trn_X, tmp_trn_y)\n",
    "            preds_logit += logit.predict_proba(val_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])/3\n",
    "            \n",
    "        gpcls = GaussianProcessClassifier(random_state=m)\n",
    "        gpcls.fit(tmp_trn_X, tmp_trn_y)\n",
    "        preds_gpcls += gpcls.predict_proba(val_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])/3\n",
    "                \n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(tmp_trn_X, tmp_trn_y)\n",
    "        preds_gnb += gnb.predict_proba(val_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])\n",
    "                \n",
    "      \n",
    "    for i in range(4):\n",
    "        val_df[f'preds_logit_{i+1}'] = preds_logit[:,i]\n",
    "        val_df[f'preds_gpcls_{i+1}'] = preds_gpcls[:,i]\n",
    "        val_df[f'preds_gnb_{i+1}'] = preds_gnb[:,i]\n",
    "\n",
    "    off_df_2.append(val_df)\n",
    "\n",
    "off_df_2 = pd.concat(off_df_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
