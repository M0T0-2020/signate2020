{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import nltk, string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "        self.stop_words = get_stop_words('en')\n",
    "        self.stop_words.append(' ')\n",
    "        self.stop_words.append('')\n",
    "    \n",
    "    def pipeline(self, df):\n",
    "        for lang in ['description']:\n",
    "            #, 'translate_es', 'translate_fr', 'translate_de', 'translate_ja']:\n",
    "            df[lang] = df[lang].apply(lambda x: self.change_text(x))\n",
    "        return df\n",
    "\n",
    "    def change_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace('ml', 'machine learning')\n",
    "        text = text.replace('machine learning', 'machinelearning')\n",
    "        text = \"\".join([char if char not in string.punctuation else ' ' for char in text])\n",
    "        text = \" \".join([self.porter.stem(char) for char in text.split(' ') if char not in self.stop_words])\n",
    "        return text\n",
    "    \n",
    "    def vectorize_tfidf(self, df):\n",
    "        vec_tfidf = TfidfVectorizer()\n",
    "        X = vec_tfidf.fit_transform(df.description.values)\n",
    "        X = pd.DataFrame(X.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "        return X\n",
    "    \n",
    "    def vectorize_cnt(self, df):\n",
    "        vec_cnt = CountVectorizer()\n",
    "        X = vec_cnt.fit_transform(df.description.values)\n",
    "        X = pd.DataFrame(X.toarray(), columns=vec_cnt.get_feature_names())\n",
    "        return X\n",
    "\n",
    "\n",
    "class Optimize_by_Optuna:\n",
    "    def __init__(self, data, features, target_colname, target_name_2=None, _objective=None):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.target = target_colname\n",
    "        if not target_colname:\n",
    "            self.target_2 = target_colname\n",
    "        else:\n",
    "            self.target_2 = target_name_2\n",
    "        self._objective = _objective\n",
    "        \n",
    "    \n",
    "    def make_score(self, y, preds):\n",
    "        s_1=1 - metrics.accuracy_score(y, preds)\n",
    "        s_2=list(self.model.best_score['valid_1'].values())[0]\n",
    "\n",
    "        return (s_1+s_2)/2\n",
    "\n",
    "    def objective(self, trial):\n",
    "                        \n",
    "        PARAMS = {#'boosting_type': 'gbdt', 'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            \n",
    "            #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "            \n",
    "            'objective': 'tweedie','metric': 'tweedie',\n",
    "            \n",
    "            'n_estimators': 1400,\n",
    "            'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "        \n",
    "\n",
    "            'tweedie_variance_power': trial.suggest_uniform('tweedie_variance_power', 1.01, 1.8),\n",
    "\n",
    "\n",
    "            'max_bin': trial.suggest_int('max_bin', 50, 300),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.4, 0.9),\n",
    "            'subsample_freq': trial.suggest_uniform('subsample_freq', 0.4, 0.9),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.03, 0.5),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 4, 2*5),\n",
    "            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.0001, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.0001, 10.0),\n",
    "        }\n",
    "        \n",
    "        score = 0\n",
    "        k = StratifiedKFold(n_splits=5)\n",
    "        for trn, val in k.split(self.data, self.data[self.target_2]):\n",
    "            train_df = self.data.iloc[trn,:]\n",
    "            val_df = self.data.iloc[val,:]\n",
    "            train_set= lgb.Dataset(train_df[self.features],  train_df[self.target])\n",
    "            val_set = lgb.Dataset(val_df[self.features],  val_df[self.target])   \n",
    "            \n",
    "            self.model = lgb.train(\n",
    "                train_set=train_set, valid_sets=[train_set, val_set], params=PARAMS, num_boost_round=3000, \n",
    "                early_stopping_rounds=200, verbose_eval=500\n",
    "                )\n",
    "                \n",
    "            preds = self.model.predict(val_df[self.features])\n",
    "            preds = np.round(preds)\n",
    "            y = val_df[self.target]\n",
    "            s = self.make_score(y, preds)\n",
    "            score+=s/5\n",
    "            \n",
    "        return score\n",
    "\n",
    "\n",
    "class Null_Importance:\n",
    "    def __init__(self, train_X, train_y, PARAMS, y_2=None):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.y_2= y_2\n",
    "        self.PARAMS = PARAMS\n",
    "\n",
    "    def make_null_importance_df(self):\n",
    "        null_importance=pd.DataFrame()\n",
    "        null_importance['col'] = self.train_X.columns.tolist()\n",
    "        try:\n",
    "            for i in range(50):\n",
    "                tmp_null_importance=[]\n",
    "                \n",
    "                _train_y = self.train_y.apply(lambda x: random.choice([0,1]))\n",
    "                _train_y_2 = self.y_2.sample(frac=1).values\n",
    "                \n",
    "                print(f\"\"\"\n",
    "                \n",
    "                Train Null Importance   {i+1}\n",
    "                \n",
    "                \"\"\" )\n",
    "                k = StratifiedKFold(n_splits=5)\n",
    "                for trn, val in k.split(self.train_X, _train_y_2):\n",
    "                    trn_X, val_X = self.train_X.iloc[trn,:], self.train_X.iloc[val,:]\n",
    "                    trn_y, val_y = _train_y.iloc[trn].astype(int), _train_y.iloc[val].astype(int)\n",
    "                    train_set = lgb.Dataset(trn_X, trn_y)\n",
    "                    val_set = lgb.Dataset(val_X, val_y)\n",
    "\n",
    "                    model = lgb.train(params=self.PARAMS,\n",
    "                                      train_set=train_set, \n",
    "                                      valid_sets=[train_set, val_set],\n",
    "                                    num_boost_round=3000, early_stopping_rounds=200, verbose_eval=500)\n",
    "                    \n",
    "                    preds = model.predict(val_X)\n",
    "                    tmp_null_importance.append(model.feature_importance('gain'))\n",
    "                null_importance[f'null_importance_{i+1}'] = np.mean(tmp_null_importance, axis=0)\n",
    "            return null_importance\n",
    "        except:\n",
    "            return null_importance\n",
    "\n",
    "    def calu_importance(self, importance_df, null_importance_df):\n",
    "        importance_df = pd.merge(\n",
    "            importance_df, null_importance_df, on='col'\n",
    "            )\n",
    "        null_importance_col = [col for col in importance_df.columns if 'null' in col]\n",
    "        null_importance=pd.DataFrame()\n",
    "        for idx, row in importance_df.iterrows():\n",
    "            acc_v = 1e-10+row['true_importance']\n",
    "            null_v = 1+np.percentile(row[null_importance_col], 75)\n",
    "            null_importance[row['col']] = [np.log(acc_v/null_v)]\n",
    "        null_importance = null_importance.T\n",
    "        return null_importance\n",
    "\n",
    "    def all_flow(self):\n",
    "        k = StratifiedKFold(n_splits=5)\n",
    "        score=[]\n",
    "        importance=[]\n",
    "\n",
    "        importance_df=pd.DataFrame()\n",
    "        importance_df['col'] = self.train_X.columns\n",
    "        print(\"\"\"\n",
    "        \n",
    "        Train True Importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        for trn, val in k.split(self.train_X, self.y_2):\n",
    "            trn_X, val_X = self.train_X.iloc[trn,:], self.train_X.iloc[val,:]\n",
    "            trn_y, val_y = self.train_y.iloc[trn].astype(int), self.train_y.iloc[val].astype(int)\n",
    "            train_set = lgb.Dataset(trn_X, trn_y)\n",
    "            val_set = lgb.Dataset(val_X, val_y)\n",
    "            \n",
    "            PARAMS['random_state']+=1\n",
    "            model = lgb.train(params=self.PARAMS, train_set=train_set, valid_sets=[train_set, val_set],\n",
    "                            num_boost_round=3000, early_stopping_rounds=200, verbose_eval=500)\n",
    "            preds = model.predict(val_X)\n",
    "            importance.append(model.feature_importance('gain'))\n",
    "        importance_df['true_importance'] = np.mean(importance, axis=0)\n",
    "        \n",
    "        print(\"\"\"\n",
    "        \n",
    "        Train Null Importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        try:\n",
    "            null_importance_df = self.make_null_importance_df()\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\"\"\n",
    "        \n",
    "        Calulate null_null_importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        null_importance = self.calu_importance(importance_df, null_importance_df)\n",
    "        null_importance = null_importance.reset_index()\n",
    "        null_importance.columns = ['col', 'score']\n",
    "        null_importance = null_importance.sort_values('score', ascending=False)\n",
    "        return null_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('train.csv'),\n",
    "    pd.read_csv('test.csv')],\n",
    "    axis=0,ignore_index=True)\n",
    "preprocessing = Preprocessing()\n",
    "df.description = df.description.apply(lambda x: preprocessing.change_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.vectorize_tfidf(df)\n",
    "X = pd.concat([df.jobflag, X], axis=1)\n",
    "train_df = X[X.jobflag.notnull()].reset_index(drop=True)\n",
    "test_df = X[X.jobflag.isnull()].drop(columns=['jobflag']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['abil', 'abl', 'accept', 'access', 'accord', 'account', 'accur', 'accuraci', 'achiev', 'acquisit', 'across', 'act', 'action', \n",
    "           'activ', 'ad', 'addit', 'address', 'adher', 'administr', 'advanc', 'advis', 'advisor', 'agil', 'agre', 'ai', 'algorithm', \n",
    "           'align', 'analys', 'analysi', 'analyst', 'analyt', 'analyz', 'api', 'appli', 'applic', 'approach', 'appropri', 'approv', \n",
    "           'architect', 'architectur', 'area', 'assembl', 'assess', 'assign', 'assist', 'audienc', 'autom', 'avail', 'aw', 'back',\n",
    "           'backend', 'base', 'basic', 'behavior', 'benefit', 'best', 'board', 'bug', 'build', 'busi', 'call', 'can', 'candid', 'capabl',\n",
    "           'capac', 'case', 'caus', 'challeng', 'chang', 'clearli', 'client', 'clinic', 'close', 'cloud', 'cluster', 'coach', 'code', \n",
    "           'collabor', 'collect', 'commerci', 'commiss', 'commun', 'compani', 'complet', 'complex', 'complianc', 'compon', 'comput', \n",
    "           'concept', 'conduct', 'confer', 'configur', 'connect', 'consist', 'construct', 'consult', 'content', 'continu', 'contract',\n",
    "           'contribut', 'control', 'coordin', 'core', 'corpor', 'correct', 'cost', 'creat', 'creation', 'creativ', 'critic', 'cross', \n",
    "           'cultur', 'current', 'custom', 'cycl', 'daili', 'dashboard', 'data', 'databas', 'dataset', 'date', 'deadlin', 'debug', 'decis',\n",
    "           'deep', 'defect', 'defin', 'definit', 'deliv', 'deliver', 'deliveri', 'demand', 'demonstr', 'depart', 'depend', 'deploy', 'depth',\n",
    "           'deriv', 'design', 'desir', 'detail', 'detect', 'determin', 'develop', 'devic', 'devop', 'differ', 'digit', 'direct', 'disciplin',\n",
    "           'discoveri', 'discuss', 'distribut', 'divers', 'document', 'domain', 'draw', 'drive', 'duti', 'dynam', 'edg', 'educ', 'effect',\n",
    "           'effici', 'effort', 'electron', 'email', 'embed', 'employe', 'enabl', 'end', 'engag', 'engin', 'enhanc', 'ensur', 'enterpris',\n",
    "           'environ', 'equip', 'erp', 'escal', 'establish', 'estim', 'etc', 'evalu', 'event', 'excel', 'execut', 'exist', 'expand', 'experi',\n",
    "           'expert', 'expertis', 'explain', 'explor', 'exploratori', 'extern', 'extract', 'face', 'facilit', 'failur', 'featur', 'feder', \n",
    "           'field', 'find', 'fix', 'flow', 'focu', 'follow', 'form', 'formul', 'framework', 'front', 'full', 'function', 'futur', 'gain',\n",
    "           'gap', 'gather', 'gener', 'global', 'go', 'goal', 'good', 'govern', 'group', 'grow', 'growth', 'guid', 'guidanc', 'hand', \n",
    "           'hardwar', 'healthcar', 'help', 'high', 'highli', 'hoc', 'idea', 'identifi', 'impact', 'implement', 'improv', 'incid', 'includ',\n",
    "           'increas', 'independ', 'individu', 'industri', 'influenc', 'inform', 'infrastructur', 'initi', 'innov', 'input', 'insight',\n",
    "           'inspect', 'instal', 'integr', 'intellig', 'interact', 'interfac', 'intern', 'interpret', 'investig', 'issu', 'iter', 'java',\n",
    "           'job', 'junior', 'keep', 'key', 'knowledg', 'languag', 'larg', 'latest', 'lead', 'leader', 'leadership', 'learn', 'level', \n",
    "           'leverag', 'librari', 'life', 'like', 'limit', 'linux', 'log', 'logic', 'machin', 'machinelearn', 'maintain', 'mainten', \n",
    "           'make', 'manag', 'manner', 'manufactur', 'map', 'market', 'materi', 'matter', 'may', 'measur', 'mechan', 'medic', 'meet',\n",
    "           'member', 'mentor', 'met', 'method', 'methodolog', 'metric', 'microsoft', 'migrat', 'mission', 'mobil', 'model', 'moder',\n",
    "           'modifi', 'modul', 'monitor', 'multi', 'multipl', 'must', 'necessari', 'need', 'net', 'network', 'new', 'next', 'non', 'novel',\n",
    "           'object', 'obtain', 'ongo', 'open', 'oper', 'opportun', 'optim', 'order', 'organ', 'organiz', 'orient', 'outcom', 'outsid',\n",
    "           'overal', 'overse', 'part', 'parti', 'particip', 'partner', 'partnership', 'pattern', 'payrol', 'peer', 'perform', 'person',\n",
    "           'personnel', 'pipelin', 'plan', 'platform', 'point', 'polici', 'posit', 'post', 'potenti', 'practic', 'pre', 'predict', 'prepar', \n",
    "           'present', 'price', 'principl', 'prior', 'priorit', 'proactiv', 'problem', 'procedur', 'process', 'produc', 'product', \n",
    "           'profession', 'program', 'progress', 'project', 'promot', 'proof', 'propos', 'prospect', 'protocol', 'prototyp','provid', \n",
    "           'purpos', 'python', 'qa', 'qualifi', 'qualiti', 'queri', 'question', 'quickli', 'real', 'recommend', 'referr', 'refin', 'regard',\n",
    "           'region', 'regul', 'regular', 'regulatori', 'relat', 'relationship', 'releas', 'relev', 'reliabl', 'report','repres', 'request',\n",
    "           'requir', 'research', 'resid', 'resolut', 'resolv', 'resourc', 'respons', 'result', 'retail', 'review', 'rigor', 'risk', 'roadmap',\n",
    "           'role', 'root', 'rule', 'run', 'safeti', 'sale', 'scalabl', 'scale', 'schedul', 'scienc', 'scientist', 'scope', 'script', 'scrum',\n",
    "           'secur', 'segment', 'select', 'self', 'sell', 'senior', 'serv', 'server', 'servic', 'set', 'share', 'show', 'simul', 'site',\n",
    "           'skill', 'small', 'softwar', 'solut', 'solv', 'sourc', 'specif', 'sql', 'stack', 'staff', 'stakehold', 'standard', 'state',\n",
    "           'statist', 'statu', 'stay', 'store', 'stori', 'strateg', 'strategi', 'stream', 'strong', 'structur', 'studi', 'subject', \n",
    "           'success', 'suggest', 'supplier', 'support', 'system', 'take', 'target', 'task', 'team', 'technic', 'techniqu', 'technolog', \n",
    "           'term','test', 'think', 'thought', 'throughout', 'time', 'timelin', 'tool', 'top', 'track', 'train', 'transform', 'translat',\n",
    "           'travel', 'trend', 'troubleshoot', 'tune', 'understand', 'unit', 'updat', 'upgrad', 'use', 'user', 'util', 'valid',\n",
    "           'valu', 'variou', 'vehicl', 'vendor', 'verif', 'verifi', 'version', 'via', 'vision', 'visual', 'way',\n",
    "           'web', 'well', 'wide', 'will', 'window', 'within', 'work', 'workflow','write']\n",
    "\n",
    "PARAMS_1={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "   'tweedie_variance_power': 1.349969119190657, 'max_bin': 212, 'subsample': 0.5774043241504451, 'subsample_freq': 0.7045972939301558, \n",
    "    'learning_rate': 0.16528226095247364, 'num_leaves': 4, 'feature_fraction': 0.9964784224971625,\n",
    "    'bagging_freq': 6, 'min_child_samples': 23, 'lambda_l1': 0.016924825494747078, 'lambda_l2': 0.0008031532180312293\n",
    "}\n",
    "\n",
    "\n",
    "PARAMS_2={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'tweedie_variance_power': 1.3014991003823067, 'max_bin': 134, 'subsample': 0.8990859498726816, 'subsample_freq': 0.5274951186330312,\n",
    "    'learning_rate': 0.3937162652059595, 'num_leaves': 5, 'feature_fraction': 0.8861294810479933, 'bagging_freq': 5,\n",
    "    'min_child_samples': 28, 'lambda_l1': 6.037171725930821, 'lambda_l2': 0.0025254105473444784\n",
    "}\n",
    "\n",
    "PARAMS_3={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    #'objective': 'tweedie','metric': 'tweedie',\n",
    "     \n",
    "    'objective': 'xentropy','metric': 'xentropy',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'max_bin': 50, 'subsample': 0.8509082362331666, 'subsample_freq': 0.6958806976511948, 'learning_rate': 0.09406169926162017,\n",
    "    'num_leaves': 7, 'feature_fraction': 0.7562554580497556, 'bagging_freq': 4, 'min_child_samples': 5, 'lambda_l1': 0.00021420978217365439,\n",
    "    'lambda_l2': 0.011867471326820044\n",
    "}\n",
    "\n",
    "PARAMS_4={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'tweedie_variance_power': 1.3572492826220748, 'max_bin': 169, 'subsample': 0.6874225607452877, 'subsample_freq': 0.5369168449326642,\n",
    "    'learning_rate': 0.0353671206084155, 'num_leaves': 8, 'feature_fraction': 0.9508830019260512, \n",
    "    'bagging_freq': 2, 'min_child_samples': 63, 'lambda_l1': 8.281467382972142, 'lambda_l2': 0.1428656656583413\n",
    "}\n",
    "\n",
    "param_list = [PARAMS_1, PARAMS_2, PARAMS_3, PARAMS_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[feature+['jobflag']]\n",
    "test_df = test_df[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>web</th>\n",
       "      <th>well</th>\n",
       "      <th>wide</th>\n",
       "      <th>will</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215403</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit  ...  web  well  wide  will  window  within  work  workflow  \\\n",
       "0       0.0  ...  0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "1       0.0  ...  0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "2       0.0  ...  0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "3       0.0  ...  0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "4       0.0  ...  0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "\n",
       "      write  jobflag  \n",
       "0  0.215403      2.0  \n",
       "1  0.000000      3.0  \n",
       "2  0.000000      4.0  \n",
       "3  0.000000      1.0  \n",
       "4  0.000000      4.0  \n",
       "\n",
       "[5 rows x 539 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>well</th>\n",
       "      <th>wide</th>\n",
       "      <th>will</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit  ...  way  web  well  wide  will  window  within      work  \\\n",
       "0       0.0  ...  0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.544329   \n",
       "1       0.0  ...  0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "2       0.0  ...  0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "3       0.0  ...  0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "4       0.0  ...  0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "\n",
       "   workflow  write  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "\n",
       "[5 rows x 538 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_offdf(train_df, feature, params_list):\n",
    "    k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    \n",
    "    y_1 = train_df.jobflag.apply(lambda x: 1 if x==1 else 0)\n",
    "    y_2 = train_df.jobflag.apply(lambda x: 1 if x==2 else 0)\n",
    "    y_3 = train_df.jobflag.apply(lambda x: 1 if x==3 else 0)\n",
    "    y_4 = train_df.jobflag.apply(lambda x: 1 if x==4 else 0)\n",
    "    \n",
    "    off_df = []\n",
    "    \n",
    "    for trn, val in k.split(train_df, train_df.jobflag):\n",
    "        train_X, val_X = train_df.iloc[trn,:][feature], train_df.iloc[val,:][feature]\n",
    "        tmp_off_df = train_df.iloc[val,:]\n",
    "        c=1\n",
    "        for y, param in zip([y_1, y_2, y_3, y_4], params_list):\n",
    "            train_y, val_y = y.iloc[trn], y.iloc[val]\n",
    "            train_set= lgb.Dataset(train_X,  train_y)\n",
    "            val_set = lgb.Dataset(val_X,  val_y)   \n",
    "\n",
    "            model = lgb.train(\n",
    "                train_set=train_set, valid_sets=[train_set, val_set], params=param, num_boost_round=3000, \n",
    "                early_stopping_rounds=200, verbose_eval=500\n",
    "            )\n",
    "            tmp_off_df[f'preds_{c}'] = model.predict(val_X)\n",
    "            c+=1\n",
    "            \n",
    "        off_df.append(tmp_off_df)\n",
    "    off_df = pd.concat(off_df, axis=0)\n",
    "    return off_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's tweedie: 1.44053\tvalid_1's tweedie: 1.46228\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's tweedie: 0.921552\tvalid_1's tweedie: 0.98783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's cross_entropy: 0.334137\tvalid_1's cross_entropy: 0.465248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.36352\tvalid_1's tweedie: 1.37861\n",
      "[1000]\ttraining's tweedie: 1.34188\tvalid_1's tweedie: 1.37521\n",
      "Early stopping, best iteration is:\n",
      "[1120]\ttraining's tweedie: 1.33762\tvalid_1's tweedie: 1.37406\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's tweedie: 1.41697\tvalid_1's tweedie: 1.46835\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's tweedie: 0.942719\tvalid_1's tweedie: 0.972171\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's cross_entropy: 0.391092\tvalid_1's cross_entropy: 0.521484\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.34764\tvalid_1's tweedie: 1.4367\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttraining's tweedie: 1.35645\tvalid_1's tweedie: 1.4355\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's tweedie: 1.40964\tvalid_1's tweedie: 1.42421\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's tweedie: 0.948356\tvalid_1's tweedie: 1.02549\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's cross_entropy: 0.325926\tvalid_1's cross_entropy: 0.498446\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.36019\tvalid_1's tweedie: 1.39731\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's tweedie: 1.35021\tvalid_1's tweedie: 1.39485\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's tweedie: 1.43018\tvalid_1's tweedie: 1.44813\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's tweedie: 0.883896\tvalid_1's tweedie: 0.97512\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's cross_entropy: 0.318781\tvalid_1's cross_entropy: 0.493539\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.36084\tvalid_1's tweedie: 1.38835\n",
      "[1000]\ttraining's tweedie: 1.34221\tvalid_1's tweedie: 1.38384\n",
      "Early stopping, best iteration is:\n",
      "[911]\ttraining's tweedie: 1.34243\tvalid_1's tweedie: 1.3837\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's tweedie: 1.39964\tvalid_1's tweedie: 1.47009\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's tweedie: 0.901108\tvalid_1's tweedie: 0.968065\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttraining's cross_entropy: 0.334429\tvalid_1's cross_entropy: 0.510753\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.34793\tvalid_1's tweedie: 1.42099\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's tweedie: 1.34645\tvalid_1's tweedie: 1.41943\n"
     ]
    }
   ],
   "source": [
    "off_df = make_offdf(train_df, feature, param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190896</td>\n",
       "      <td>-0.489229</td>\n",
       "      <td>-0.259152</td>\n",
       "      <td>0.506817</td>\n",
       "      <td>0.147409</td>\n",
       "      <td>-0.446349</td>\n",
       "      <td>-0.152492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.190896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.345280</td>\n",
       "      <td>-0.182900</td>\n",
       "      <td>0.119368</td>\n",
       "      <td>0.377547</td>\n",
       "      <td>-0.197172</td>\n",
       "      <td>-0.170386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>-0.489229</td>\n",
       "      <td>-0.345280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.468737</td>\n",
       "      <td>-0.392012</td>\n",
       "      <td>-0.224782</td>\n",
       "      <td>0.584475</td>\n",
       "      <td>-0.108653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>-0.259152</td>\n",
       "      <td>-0.182900</td>\n",
       "      <td>-0.468737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.126361</td>\n",
       "      <td>-0.176079</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>0.430291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_1</th>\n",
       "      <td>0.506817</td>\n",
       "      <td>0.119368</td>\n",
       "      <td>-0.392012</td>\n",
       "      <td>-0.126361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.286276</td>\n",
       "      <td>-0.648559</td>\n",
       "      <td>-0.209572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_2</th>\n",
       "      <td>0.147409</td>\n",
       "      <td>0.377547</td>\n",
       "      <td>-0.224782</td>\n",
       "      <td>-0.176079</td>\n",
       "      <td>0.286276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.372438</td>\n",
       "      <td>-0.319862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_3</th>\n",
       "      <td>-0.446349</td>\n",
       "      <td>-0.197172</td>\n",
       "      <td>0.584475</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.648559</td>\n",
       "      <td>-0.372438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds_4</th>\n",
       "      <td>-0.152492</td>\n",
       "      <td>-0.170386</td>\n",
       "      <td>-0.108653</td>\n",
       "      <td>0.430291</td>\n",
       "      <td>-0.209572</td>\n",
       "      <td>-0.319862</td>\n",
       "      <td>-0.139463</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1.0       2.0       3.0       4.0   preds_1   preds_2   preds_3  \\\n",
       "1.0      1.000000 -0.190896 -0.489229 -0.259152  0.506817  0.147409 -0.446349   \n",
       "2.0     -0.190896  1.000000 -0.345280 -0.182900  0.119368  0.377547 -0.197172   \n",
       "3.0     -0.489229 -0.345280  1.000000 -0.468737 -0.392012 -0.224782  0.584475   \n",
       "4.0     -0.259152 -0.182900 -0.468737  1.000000 -0.126361 -0.176079 -0.113225   \n",
       "preds_1  0.506817  0.119368 -0.392012 -0.126361  1.000000  0.286276 -0.648559   \n",
       "preds_2  0.147409  0.377547 -0.224782 -0.176079  0.286276  1.000000 -0.372438   \n",
       "preds_3 -0.446349 -0.197172  0.584475 -0.113225 -0.648559 -0.372438  1.000000   \n",
       "preds_4 -0.152492 -0.170386 -0.108653  0.430291 -0.209572 -0.319862 -0.139463   \n",
       "\n",
       "          preds_4  \n",
       "1.0     -0.152492  \n",
       "2.0     -0.170386  \n",
       "3.0     -0.108653  \n",
       "4.0      0.430291  \n",
       "preds_1 -0.209572  \n",
       "preds_2 -0.319862  \n",
       "preds_3 -0.139463  \n",
       "preds_4  1.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    pd.get_dummies(off_df.jobflag)[[1,2,3,4]],\n",
    "    off_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "], axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = off_df.jobflag.value_counts().min()\n",
    "min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.038996</td>\n",
       "      <td>0.071379</td>\n",
       "      <td>0.901825</td>\n",
       "      <td>0.039188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.229664</td>\n",
       "      <td>0.057823</td>\n",
       "      <td>0.621675</td>\n",
       "      <td>0.294201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131232</td>\n",
       "      <td>0.032734</td>\n",
       "      <td>0.604222</td>\n",
       "      <td>0.263042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.106060</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.462804</td>\n",
       "      <td>0.409050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.048459</td>\n",
       "      <td>0.600843</td>\n",
       "      <td>0.218269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.063779</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.897799</td>\n",
       "      <td>0.059237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120459</td>\n",
       "      <td>0.053776</td>\n",
       "      <td>0.382556</td>\n",
       "      <td>0.502791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.175510</td>\n",
       "      <td>0.072444</td>\n",
       "      <td>0.513700</td>\n",
       "      <td>0.242473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.457676</td>\n",
       "      <td>0.361673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146945</td>\n",
       "      <td>0.146437</td>\n",
       "      <td>0.542121</td>\n",
       "      <td>0.164349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "447    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2104   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "474    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2792   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "830    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1931   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "621    0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1598   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2068   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "46     0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "      acquisit  ...  window  within  work  workflow  write  jobflag   preds_1  \\\n",
       "447        0.0  ...     0.0     0.0   0.0       0.0    0.0      3.0  0.038996   \n",
       "2104       0.0  ...     0.0     0.0   0.0       0.0    0.0      3.0  0.229664   \n",
       "474        0.0  ...     0.0     0.0   0.0       0.0    0.0      1.0  0.131232   \n",
       "2792       0.0  ...     0.0     0.0   0.0       0.0    0.0      2.0  0.106060   \n",
       "830        0.0  ...     0.0     0.0   0.0       0.0    0.0      3.0  0.155340   \n",
       "1931       0.0  ...     0.0     0.0   0.0       0.0    0.0      3.0  0.063779   \n",
       "621        0.0  ...     0.0     0.0   0.0       0.0    0.0      1.0  0.120459   \n",
       "1598       0.0  ...     0.0     0.0   0.0       0.0    0.0      3.0  0.175510   \n",
       "2068       0.0  ...     0.0     0.0   0.0       0.0    0.0      4.0  0.112773   \n",
       "46         0.0  ...     0.0     0.0   0.0       0.0    0.0      1.0  0.146945   \n",
       "\n",
       "       preds_2   preds_3   preds_4  \n",
       "447   0.071379  0.901825  0.039188  \n",
       "2104  0.057823  0.621675  0.294201  \n",
       "474   0.032734  0.604222  0.263042  \n",
       "2792  0.027210  0.462804  0.409050  \n",
       "830   0.048459  0.600843  0.218269  \n",
       "1931  0.013921  0.897799  0.059237  \n",
       "621   0.053776  0.382556  0.502791  \n",
       "1598  0.072444  0.513700  0.242473  \n",
       "2068  0.028752  0.457676  0.361673  \n",
       "46    0.146437  0.542121  0.164349  \n",
       "\n",
       "[10 rows x 543 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_df.sample(n=10, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf9871c89034681b71982cd01eb4386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7721b21e3de14027820efe375ce8ab3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1c341a904e4f0e86e28c1c71f91746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0337b7d464664d9198efff5f6104e420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333dd4660b0d49d4876663558068f8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "off_df_2=[]\n",
    "for trn, val in k.split(train_df, train_df.jobflag):\n",
    "    trn_df = off_df.iloc[trn,:]\n",
    "    val_df  =  off_df.iloc[val,:]\n",
    "    \n",
    "    min_value = trn_df.jobflag.value_counts().min()\n",
    "    \n",
    "    preds = np.zeros(shape=(len(val_df),4))\n",
    "    \n",
    "    for i in tqdm(range(300)):\n",
    "        tmp_trn_df = pd.concat(\n",
    "        [trn_df[trn_df.jobflag==1].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==2].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==3].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==4].sample(n=min_value, random_state=i)], axis=0).reset_index(drop=True)\n",
    "        tmp_trn_X = tmp_trn_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "        tmp_trn_y = tmp_trn_df['jobflag']\n",
    "        \n",
    "        \n",
    "        for penalty  in [ 'l2']:\n",
    "            for m in range(20):\n",
    "                logit = LogisticRegression(penalty=penalty, random_state=m)\n",
    "                logit.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #ridge_cls = RidgeClassifier()\n",
    "                    #ridge_cls.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #kncls = KNeighborsClassifier(n_neighbors=4)\n",
    "                    #kncls.fit(tmp_trn_X, tmp_trn_y)\n",
    "                preds += logit.predict_proba(val_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])\n",
    "        \n",
    "    val_df[f'preds'] = np.argmax(preds, axis=1)+1\n",
    "    off_df_2.append(val_df)\n",
    "off_df_2 = pd.concat(off_df_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5530455910237906"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(off_df_2.jobflag, off_df_2.preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27daea3bfc8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "cnfn_matrix = pd.DataFrame(metrics.confusion_matrix(off_df_2.jobflag, off_df_2.preds))\n",
    "#cnfn_matrix.index = \n",
    "sns.heatmap(cnfn_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>122</td>\n",
       "      <td>85</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>1002</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2    3\n",
       "0  334  100    82  108\n",
       "1   96  122    85   45\n",
       "2   66   50  1002  258\n",
       "3   52   13   170  348"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnfn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
