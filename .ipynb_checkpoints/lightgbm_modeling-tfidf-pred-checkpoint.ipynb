{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import nltk, string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import optuna\n",
    "\n",
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "        self.stop_words = get_stop_words('en')\n",
    "        self.stop_words.append(' ')\n",
    "        self.stop_words.append('')\n",
    "    \n",
    "    def pipeline(self, df):\n",
    "        for lang in ['description']:\n",
    "            #, 'translate_es', 'translate_fr', 'translate_de', 'translate_ja']:\n",
    "            df[lang] = df[lang].apply(lambda x: self.change_text(x))\n",
    "        return df\n",
    "\n",
    "    def change_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace('ml', 'machine learning')\n",
    "        text = text.replace('machine learning', 'machinelearning')\n",
    "        text = \"\".join([char if char not in string.punctuation else ' ' for char in text])\n",
    "        text = \" \".join([self.porter.stem(char) for char in text.split(' ') if char not in self.stop_words])\n",
    "        return text\n",
    "    \n",
    "    def vectorize_tfidf(self, df):\n",
    "        vec_tfidf = TfidfVectorizer()\n",
    "        X = vec_tfidf.fit_transform(df.description.values)\n",
    "        X = pd.DataFrame(X.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "        return X\n",
    "    \n",
    "    def vectorize_cnt(self, df):\n",
    "        vec_cnt = CountVectorizer()\n",
    "        X = vec_cnt.fit_transform(df.description.values)\n",
    "        X = pd.DataFrame(X.toarray(), columns=vec_cnt.get_feature_names())\n",
    "        return X\n",
    "\n",
    "\n",
    "class Optimize_by_Optuna:\n",
    "    def __init__(self, data, features, target_colname, target_name_2=None, _objective=None):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.target = target_colname\n",
    "        if not target_colname:\n",
    "            self.target_2 = target_colname\n",
    "        else:\n",
    "            self.target_2 = target_name_2\n",
    "        self._objective = _objective\n",
    "        \n",
    "    \n",
    "    def make_score(self, y, preds):\n",
    "        s_1=1 - metrics.accuracy_score(y, preds)\n",
    "        s_2=list(self.model.best_score['valid_1'].values())[0]\n",
    "\n",
    "        return (s_1+s_2)/2\n",
    "\n",
    "    def objective(self, trial):\n",
    "                        \n",
    "        PARAMS = {#'boosting_type': 'gbdt', 'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            \n",
    "            #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "            \n",
    "            'objective': 'tweedie','metric': 'tweedie',\n",
    "            \n",
    "            'n_estimators': 1400,\n",
    "            'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "        \n",
    "\n",
    "            'tweedie_variance_power': trial.suggest_uniform('tweedie_variance_power', 1.01, 1.8),\n",
    "\n",
    "\n",
    "            'max_bin': trial.suggest_int('max_bin', 50, 300),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.4, 0.9),\n",
    "            'subsample_freq': trial.suggest_uniform('subsample_freq', 0.4, 0.9),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.03, 0.5),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 4, 2*5),\n",
    "            'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.0001, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.0001, 10.0),\n",
    "        }\n",
    "        \n",
    "        score = 0\n",
    "        k = StratifiedKFold(n_splits=5)\n",
    "        for trn, val in k.split(self.data, self.data[self.target_2]):\n",
    "            train_df = self.data.iloc[trn,:]\n",
    "            val_df = self.data.iloc[val,:]\n",
    "            train_set= lgb.Dataset(train_df[self.features],  train_df[self.target])\n",
    "            val_set = lgb.Dataset(val_df[self.features],  val_df[self.target])   \n",
    "            \n",
    "            self.model = lgb.train(\n",
    "                train_set=train_set, valid_sets=[train_set, val_set], params=PARAMS, num_boost_round=3000, \n",
    "                early_stopping_rounds=200, verbose_eval=500\n",
    "                )\n",
    "                \n",
    "            preds = self.model.predict(val_df[self.features])\n",
    "            preds = np.round(preds)\n",
    "            y = val_df[self.target]\n",
    "            s = self.make_score(y, preds)\n",
    "            score+=s/5\n",
    "            \n",
    "        return score\n",
    "\n",
    "\n",
    "class Null_Importance:\n",
    "    def __init__(self, train_X, train_y, PARAMS, y_2=None):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.y_2= y_2\n",
    "        self.PARAMS = PARAMS\n",
    "\n",
    "    def make_null_importance_df(self):\n",
    "        null_importance=pd.DataFrame()\n",
    "        null_importance['col'] = self.train_X.columns.tolist()\n",
    "        try:\n",
    "            for i in range(50):\n",
    "                tmp_null_importance=[]\n",
    "                \n",
    "                _train_y = self.train_y.apply(lambda x: random.choice([0,1]))\n",
    "                _train_y_2 = self.y_2.sample(frac=1).values\n",
    "                \n",
    "                print(f\"\"\"\n",
    "                \n",
    "                Train Null Importance   {i+1}\n",
    "                \n",
    "                \"\"\" )\n",
    "                k = StratifiedKFold(n_splits=5)\n",
    "                for trn, val in k.split(self.train_X, _train_y_2):\n",
    "                    trn_X, val_X = self.train_X.iloc[trn,:], self.train_X.iloc[val,:]\n",
    "                    trn_y, val_y = _train_y.iloc[trn].astype(int), _train_y.iloc[val].astype(int)\n",
    "                    train_set = lgb.Dataset(trn_X, trn_y)\n",
    "                    val_set = lgb.Dataset(val_X, val_y)\n",
    "\n",
    "                    model = lgb.train(params=self.PARAMS,\n",
    "                                      train_set=train_set, \n",
    "                                      valid_sets=[train_set, val_set],\n",
    "                                    num_boost_round=3000, early_stopping_rounds=200, verbose_eval=500)\n",
    "                    \n",
    "                    preds = model.predict(val_X)\n",
    "                    tmp_null_importance.append(model.feature_importance('gain'))\n",
    "                null_importance[f'null_importance_{i+1}'] = np.mean(tmp_null_importance, axis=0)\n",
    "            return null_importance\n",
    "        except:\n",
    "            return null_importance\n",
    "\n",
    "    def calu_importance(self, importance_df, null_importance_df):\n",
    "        importance_df = pd.merge(\n",
    "            importance_df, null_importance_df, on='col'\n",
    "            )\n",
    "        null_importance_col = [col for col in importance_df.columns if 'null' in col]\n",
    "        null_importance=pd.DataFrame()\n",
    "        for idx, row in importance_df.iterrows():\n",
    "            acc_v = 1e-10+row['true_importance']\n",
    "            null_v = 1+np.percentile(row[null_importance_col], 75)\n",
    "            null_importance[row['col']] = [np.log(acc_v/null_v)]\n",
    "        null_importance = null_importance.T\n",
    "        return null_importance\n",
    "\n",
    "    def all_flow(self):\n",
    "        k = StratifiedKFold(n_splits=5)\n",
    "        score=[]\n",
    "        importance=[]\n",
    "\n",
    "        importance_df=pd.DataFrame()\n",
    "        importance_df['col'] = self.train_X.columns\n",
    "        print(\"\"\"\n",
    "        \n",
    "        Train True Importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        for trn, val in k.split(self.train_X, self.y_2):\n",
    "            trn_X, val_X = self.train_X.iloc[trn,:], self.train_X.iloc[val,:]\n",
    "            trn_y, val_y = self.train_y.iloc[trn].astype(int), self.train_y.iloc[val].astype(int)\n",
    "            train_set = lgb.Dataset(trn_X, trn_y)\n",
    "            val_set = lgb.Dataset(val_X, val_y)\n",
    "            \n",
    "            PARAMS['random_state']+=1\n",
    "            model = lgb.train(params=self.PARAMS, train_set=train_set, valid_sets=[train_set, val_set],\n",
    "                            num_boost_round=3000, early_stopping_rounds=200, verbose_eval=500)\n",
    "            preds = model.predict(val_X)\n",
    "            importance.append(model.feature_importance('gain'))\n",
    "        importance_df['true_importance'] = np.mean(importance, axis=0)\n",
    "        \n",
    "        print(\"\"\"\n",
    "        \n",
    "        Train Null Importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        try:\n",
    "            null_importance_df = self.make_null_importance_df()\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\"\"\n",
    "        \n",
    "        Calulate null_null_importance\n",
    "        \n",
    "        \"\"\" )\n",
    "        null_importance = self.calu_importance(importance_df, null_importance_df)\n",
    "        null_importance = null_importance.reset_index()\n",
    "        null_importance.columns = ['col', 'score']\n",
    "        null_importance = null_importance.sort_values('score', ascending=False)\n",
    "        return null_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/kanoumotoharu/Documents/signate_std_2020/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('../train.csv'),\n",
    "    pd.read_csv('../test.csv')],\n",
    "    axis=0,ignore_index=True)\n",
    "preprocessing = Preprocessing()\n",
    "df.description = df.description.apply(lambda x: preprocessing.change_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.vectorize_tfidf(df)\n",
    "X = pd.concat([df.jobflag, X], axis=1)\n",
    "train_df = X[X.jobflag.notnull()].reset_index(drop=True)\n",
    "test_df = X[X.jobflag.isnull()].drop(columns=['jobflag']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['abil', 'abl', 'accept', 'access', 'accord', 'account', 'accur', 'accuraci', 'achiev', 'acquisit', 'across', 'act', 'action', \n",
    "           'activ', 'ad', 'addit', 'address', 'adher', 'administr', 'advanc', 'advis', 'advisor', 'agil', 'agre', 'ai', 'algorithm', \n",
    "           'align', 'analys', 'analysi', 'analyst', 'analyt', 'analyz', 'api', 'appli', 'applic', 'approach', 'appropri', 'approv', \n",
    "           'architect', 'architectur', 'area', 'assembl', 'assess', 'assign', 'assist', 'audienc', 'autom', 'avail', 'aw', 'back',\n",
    "           'backend', 'base', 'basic', 'behavior', 'benefit', 'best', 'board', 'bug', 'build', 'busi', 'call', 'can', 'candid', 'capabl',\n",
    "           'capac', 'case', 'caus', 'challeng', 'chang', 'clearli', 'client', 'clinic', 'close', 'cloud', 'cluster', 'coach', 'code', \n",
    "           'collabor', 'collect', 'commerci', 'commiss', 'commun', 'compani', 'complet', 'complex', 'complianc', 'compon', 'comput', \n",
    "           'concept', 'conduct', 'confer', 'configur', 'connect', 'consist', 'construct', 'consult', 'content', 'continu', 'contract',\n",
    "           'contribut', 'control', 'coordin', 'core', 'corpor', 'correct', 'cost', 'creat', 'creation', 'creativ', 'critic', 'cross', \n",
    "           'cultur', 'current', 'custom', 'cycl', 'daili', 'dashboard', 'data', 'databas', 'dataset', 'date', 'deadlin', 'debug', 'decis',\n",
    "           'deep', 'defect', 'defin', 'definit', 'deliv', 'deliver', 'deliveri', 'demand', 'demonstr', 'depart', 'depend', 'deploy', 'depth',\n",
    "           'deriv', 'design', 'desir', 'detail', 'detect', 'determin', 'develop', 'devic', 'devop', 'differ', 'digit', 'direct', 'disciplin',\n",
    "           'discoveri', 'discuss', 'distribut', 'divers', 'document', 'domain', 'draw', 'drive', 'duti', 'dynam', 'edg', 'educ', 'effect',\n",
    "           'effici', 'effort', 'electron', 'email', 'embed', 'employe', 'enabl', 'end', 'engag', 'engin', 'enhanc', 'ensur', 'enterpris',\n",
    "           'environ', 'equip', 'erp', 'escal', 'establish', 'estim', 'etc', 'evalu', 'event', 'excel', 'execut', 'exist', 'expand', 'experi',\n",
    "           'expert', 'expertis', 'explain', 'explor', 'exploratori', 'extern', 'extract', 'face', 'facilit', 'failur', 'featur', 'feder', \n",
    "           'field', 'find', 'fix', 'flow', 'focu', 'follow', 'form', 'formul', 'framework', 'front', 'full', 'function', 'futur', 'gain',\n",
    "           'gap', 'gather', 'gener', 'global', 'go', 'goal', 'good', 'govern', 'group', 'grow', 'growth', 'guid', 'guidanc', 'hand', \n",
    "           'hardwar', 'healthcar', 'help', 'high', 'highli', 'hoc', 'idea', 'identifi', 'impact', 'implement', 'improv', 'incid', 'includ',\n",
    "           'increas', 'independ', 'individu', 'industri', 'influenc', 'inform', 'infrastructur', 'initi', 'innov', 'input', 'insight',\n",
    "           'inspect', 'instal', 'integr', 'intellig', 'interact', 'interfac', 'intern', 'interpret', 'investig', 'issu', 'iter', 'java',\n",
    "           'job', 'junior', 'keep', 'key', 'knowledg', 'languag', 'larg', 'latest', 'lead', 'leader', 'leadership', 'learn', 'level', \n",
    "           'leverag', 'librari', 'life', 'like', 'limit', 'linux', 'log', 'logic', 'machin', 'machinelearn', 'maintain', 'mainten', \n",
    "           'make', 'manag', 'manner', 'manufactur', 'map', 'market', 'materi', 'matter', 'may', 'measur', 'mechan', 'medic', 'meet',\n",
    "           'member', 'mentor', 'met', 'method', 'methodolog', 'metric', 'microsoft', 'migrat', 'mission', 'mobil', 'model', 'moder',\n",
    "           'modifi', 'modul', 'monitor', 'multi', 'multipl', 'must', 'necessari', 'need', 'net', 'network', 'new', 'next', 'non', 'novel',\n",
    "           'object', 'obtain', 'ongo', 'open', 'oper', 'opportun', 'optim', 'order', 'organ', 'organiz', 'orient', 'outcom', 'outsid',\n",
    "           'overal', 'overse', 'part', 'parti', 'particip', 'partner', 'partnership', 'pattern', 'payrol', 'peer', 'perform', 'person',\n",
    "           'personnel', 'pipelin', 'plan', 'platform', 'point', 'polici', 'posit', 'post', 'potenti', 'practic', 'pre', 'predict', 'prepar', \n",
    "           'present', 'price', 'principl', 'prior', 'priorit', 'proactiv', 'problem', 'procedur', 'process', 'produc', 'product', \n",
    "           'profession', 'program', 'progress', 'project', 'promot', 'proof', 'propos', 'prospect', 'protocol', 'prototyp','provid', \n",
    "           'purpos', 'python', 'qa', 'qualifi', 'qualiti', 'queri', 'question', 'quickli', 'real', 'recommend', 'referr', 'refin', 'regard',\n",
    "           'region', 'regul', 'regular', 'regulatori', 'relat', 'relationship', 'releas', 'relev', 'reliabl', 'report','repres', 'request',\n",
    "           'requir', 'research', 'resid', 'resolut', 'resolv', 'resourc', 'respons', 'result', 'retail', 'review', 'rigor', 'risk', 'roadmap',\n",
    "           'role', 'root', 'rule', 'run', 'safeti', 'sale', 'scalabl', 'scale', 'schedul', 'scienc', 'scientist', 'scope', 'script', 'scrum',\n",
    "           'secur', 'segment', 'select', 'self', 'sell', 'senior', 'serv', 'server', 'servic', 'set', 'share', 'show', 'simul', 'site',\n",
    "           'skill', 'small', 'softwar', 'solut', 'solv', 'sourc', 'specif', 'sql', 'stack', 'staff', 'stakehold', 'standard', 'state',\n",
    "           'statist', 'statu', 'stay', 'store', 'stori', 'strateg', 'strategi', 'stream', 'strong', 'structur', 'studi', 'subject', \n",
    "           'success', 'suggest', 'supplier', 'support', 'system', 'take', 'target', 'task', 'team', 'technic', 'techniqu', 'technolog', \n",
    "           'term','test', 'think', 'thought', 'throughout', 'time', 'timelin', 'tool', 'top', 'track', 'train', 'transform', 'translat',\n",
    "           'travel', 'trend', 'troubleshoot', 'tune', 'understand', 'unit', 'updat', 'upgrad', 'use', 'user', 'util', 'valid',\n",
    "           'valu', 'variou', 'vehicl', 'vendor', 'verif', 'verifi', 'version', 'via', 'vision', 'visual', 'way',\n",
    "           'web', 'well', 'wide', 'will', 'window', 'within', 'work', 'workflow','write']\n",
    "\n",
    "PARAMS_1={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "   'tweedie_variance_power': 1.349969119190657, 'max_bin': 212, 'subsample': 0.5774043241504451, 'subsample_freq': 0.7045972939301558, \n",
    "    'learning_rate': 0.16528226095247364, 'num_leaves': 4, 'feature_fraction': 0.9964784224971625,\n",
    "    'bagging_freq': 6, 'min_child_samples': 23, 'lambda_l1': 0.016924825494747078, 'lambda_l2': 0.0008031532180312293\n",
    "}\n",
    "\n",
    "\n",
    "PARAMS_2={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'tweedie_variance_power': 1.3014991003823067, 'max_bin': 134, 'subsample': 0.8990859498726816, 'subsample_freq': 0.5274951186330312,\n",
    "    'learning_rate': 0.3937162652059595, 'num_leaves': 5, 'feature_fraction': 0.8861294810479933, 'bagging_freq': 5,\n",
    "    'min_child_samples': 28, 'lambda_l1': 6.037171725930821, 'lambda_l2': 0.0025254105473444784\n",
    "}\n",
    "\n",
    "PARAMS_3={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    #'objective': 'tweedie','metric': 'tweedie',\n",
    "     \n",
    "    'objective': 'xentropy','metric': 'xentropy',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'max_bin': 50, 'subsample': 0.8509082362331666, 'subsample_freq': 0.6958806976511948, 'learning_rate': 0.09406169926162017,\n",
    "    'num_leaves': 7, 'feature_fraction': 0.7562554580497556, 'bagging_freq': 4, 'min_child_samples': 5, 'lambda_l1': 0.00021420978217365439,\n",
    "    'lambda_l2': 0.011867471326820044\n",
    "}\n",
    "\n",
    "PARAMS_4={\n",
    "    'boosting_type': 'gbdt',\n",
    "    \n",
    "    #'objective': 'multiclass','metric': 'multiclass', 'num_class':4,\n",
    "    \n",
    "    'objective': 'tweedie','metric': 'tweedie',\n",
    "    \n",
    "    'n_estimators': 1400,\n",
    "    'boost_from_average': False,'verbose': -1,'random_state':2020,\n",
    "    \n",
    "    'tweedie_variance_power': 1.3572492826220748, 'max_bin': 169, 'subsample': 0.6874225607452877, 'subsample_freq': 0.5369168449326642,\n",
    "    'learning_rate': 0.0353671206084155, 'num_leaves': 8, 'feature_fraction': 0.9508830019260512, \n",
    "    'bagging_freq': 2, 'min_child_samples': 63, 'lambda_l1': 8.281467382972142, 'lambda_l2': 0.1428656656583413\n",
    "}\n",
    "\n",
    "param_list = [PARAMS_1, PARAMS_2, PARAMS_3, PARAMS_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[feature+['jobflag']]\n",
    "test_df = test_df[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>web</th>\n",
       "      <th>well</th>\n",
       "      <th>wide</th>\n",
       "      <th>will</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215403</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit   ...     web  well  wide  will  window  within  work  workflow  \\\n",
       "0       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "1       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "2       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "3       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "4       0.0   ...     0.0   0.0   0.0   0.0     0.0     0.0   0.0       0.0   \n",
       "\n",
       "      write  jobflag  \n",
       "0  0.215403      2.0  \n",
       "1  0.000000      3.0  \n",
       "2  0.000000      4.0  \n",
       "3  0.000000      1.0  \n",
       "4  0.000000      4.0  \n",
       "\n",
       "[5 rows x 539 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>web</th>\n",
       "      <th>well</th>\n",
       "      <th>wide</th>\n",
       "      <th>will</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit  ...    way  web  well  wide  will  window  within      work  \\\n",
       "0       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.544329   \n",
       "1       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "2       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "3       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "4       0.0  ...    0.0  0.0   0.0   0.0   0.0     0.0     0.0  0.000000   \n",
       "\n",
       "   workflow  write  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "\n",
       "[5 rows x 538 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_offdf(train_df, test_df, feature, params_list):\n",
    "    k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    \n",
    "    y_1 = train_df.jobflag.apply(lambda x: 1 if x==1 else 0)\n",
    "    y_2 = train_df.jobflag.apply(lambda x: 1 if x==2 else 0)\n",
    "    y_3 = train_df.jobflag.apply(lambda x: 1 if x==3 else 0)\n",
    "    y_4 = train_df.jobflag.apply(lambda x: 1 if x==4 else 0)\n",
    "    \n",
    "    off_df = []\n",
    "    for i in range(4):\n",
    "        test_df[f'preds_{i+1}']=0\n",
    "    \n",
    "    for trn, val in k.split(train_df, train_df.jobflag):\n",
    "        train_X, val_X = train_df.iloc[trn,:][feature], train_df.iloc[val,:][feature]\n",
    "        tmp_off_df = train_df.iloc[val,:]\n",
    "        c=1\n",
    "        for y, param in zip([y_1, y_2, y_3, y_4], params_list):\n",
    "            tmp_off_df[f'preds_{c}']=0\n",
    "            for _ in range(5):\n",
    "                train_y, val_y = y.iloc[trn], y.iloc[val]\n",
    "                train_set= lgb.Dataset(train_X,  train_y)\n",
    "                val_set = lgb.Dataset(val_X,  val_y)   \n",
    "\n",
    "                model = lgb.train(\n",
    "                    train_set=train_set, valid_sets=[train_set, val_set], params=param, num_boost_round=3000, \n",
    "                    early_stopping_rounds=200, verbose_eval=500\n",
    "                )\n",
    "                tmp_off_df[f'preds_{c}'] += model.predict(val_X)/5\n",
    "                param['random_state']+=1\n",
    "                \n",
    "                test_df[f'preds_{c}'] += model.predict(test_df[feature])/5\n",
    "                \n",
    "            c+=1\n",
    "        \n",
    "        off_df.append(tmp_off_df)\n",
    "    \n",
    "    for i in range(4):\n",
    "        test_df[f'preds_{i+1}']/=5\n",
    "    \n",
    "    off_df = pd.concat(off_df, axis=0)\n",
    "    return off_df.reset_index(drop=True), test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's tweedie: 1.4128\tvalid_1's tweedie: 1.46191\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's tweedie: 1.4308\tvalid_1's tweedie: 1.46305\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's tweedie: 1.42932\tvalid_1's tweedie: 1.46299\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's tweedie: 1.43488\tvalid_1's tweedie: 1.45978\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's tweedie: 1.39601\tvalid_1's tweedie: 1.45548\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's tweedie: 0.944998\tvalid_1's tweedie: 1.00524\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's tweedie: 0.924731\tvalid_1's tweedie: 1.00842\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's tweedie: 0.968658\tvalid_1's tweedie: 1.01463\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's tweedie: 0.946281\tvalid_1's tweedie: 1.01733\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's tweedie: 0.929233\tvalid_1's tweedie: 1.0109\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's cross_entropy: 0.37454\tvalid_1's cross_entropy: 0.502626\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's cross_entropy: 0.36895\tvalid_1's cross_entropy: 0.506668\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's cross_entropy: 0.365836\tvalid_1's cross_entropy: 0.503969\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's cross_entropy: 0.346408\tvalid_1's cross_entropy: 0.506784\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's cross_entropy: 0.387256\tvalid_1's cross_entropy: 0.499746\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.3571\tvalid_1's tweedie: 1.39607\n",
      "[1000]\ttraining's tweedie: 1.33516\tvalid_1's tweedie: 1.39167\n",
      "Early stopping, best iteration is:\n",
      "[968]\ttraining's tweedie: 1.33617\tvalid_1's tweedie: 1.3911\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35825\tvalid_1's tweedie: 1.39685\n",
      "Early stopping, best iteration is:\n",
      "[610]\ttraining's tweedie: 1.3523\tvalid_1's tweedie: 1.39527\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.3581\tvalid_1's tweedie: 1.39669\n",
      "[1000]\ttraining's tweedie: 1.3372\tvalid_1's tweedie: 1.39282\n",
      "Early stopping, best iteration is:\n",
      "[815]\ttraining's tweedie: 1.34364\tvalid_1's tweedie: 1.39205\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35729\tvalid_1's tweedie: 1.39599\n",
      "[1000]\ttraining's tweedie: 1.33511\tvalid_1's tweedie: 1.39451\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttraining's tweedie: 1.34043\tvalid_1's tweedie: 1.39355\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35714\tvalid_1's tweedie: 1.39671\n",
      "[1000]\ttraining's tweedie: 1.33416\tvalid_1's tweedie: 1.39317\n",
      "Early stopping, best iteration is:\n",
      "[1086]\ttraining's tweedie: 1.33112\tvalid_1's tweedie: 1.39121\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's tweedie: 1.41341\tvalid_1's tweedie: 1.42911\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's tweedie: 1.38614\tvalid_1's tweedie: 1.4184\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's tweedie: 1.41961\tvalid_1's tweedie: 1.43197\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's tweedie: 1.41549\tvalid_1's tweedie: 1.42268\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's tweedie: 1.41572\tvalid_1's tweedie: 1.42528\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's tweedie: 0.923276\tvalid_1's tweedie: 0.975829\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's tweedie: 0.946432\tvalid_1's tweedie: 0.973895\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's tweedie: 0.935151\tvalid_1's tweedie: 0.972021\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's tweedie: 0.913168\tvalid_1's tweedie: 0.969647\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's tweedie: 0.919868\tvalid_1's tweedie: 0.967793\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttraining's cross_entropy: 0.341628\tvalid_1's cross_entropy: 0.483818\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's cross_entropy: 0.339871\tvalid_1's cross_entropy: 0.47945\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's cross_entropy: 0.346877\tvalid_1's cross_entropy: 0.484102\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's cross_entropy: 0.229588\tvalid_1's cross_entropy: 0.488581\n",
      "Early stopping, best iteration is:\n",
      "[417]\ttraining's cross_entropy: 0.255624\tvalid_1's cross_entropy: 0.477827\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's cross_entropy: 0.334484\tvalid_1's cross_entropy: 0.477825\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's tweedie: 1.38241\tvalid_1's tweedie: 1.45725\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's tweedie: 1.37553\tvalid_1's tweedie: 1.46138\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's tweedie: 1.37637\tvalid_1's tweedie: 1.4578\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's tweedie: 1.37261\tvalid_1's tweedie: 1.45941\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's tweedie: 1.38001\tvalid_1's tweedie: 1.46028\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's tweedie: 1.39409\tvalid_1's tweedie: 1.43527\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's tweedie: 1.42004\tvalid_1's tweedie: 1.43782\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's tweedie: 1.37187\tvalid_1's tweedie: 1.43651\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's tweedie: 1.39068\tvalid_1's tweedie: 1.43445\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's tweedie: 1.42119\tvalid_1's tweedie: 1.44449\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's tweedie: 0.956413\tvalid_1's tweedie: 0.989236\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's tweedie: 0.94777\tvalid_1's tweedie: 0.992164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's tweedie: 0.924679\tvalid_1's tweedie: 0.987378\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's tweedie: 0.919343\tvalid_1's tweedie: 0.982616\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's tweedie: 0.93519\tvalid_1's tweedie: 0.988798\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttraining's cross_entropy: 0.36437\tvalid_1's cross_entropy: 0.520173\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's cross_entropy: 0.33072\tvalid_1's cross_entropy: 0.530024\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's cross_entropy: 0.34099\tvalid_1's cross_entropy: 0.526069\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's cross_entropy: 0.447103\tvalid_1's cross_entropy: 0.527678\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's cross_entropy: 0.377833\tvalid_1's cross_entropy: 0.525478\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35868\tvalid_1's tweedie: 1.38431\n",
      "Early stopping, best iteration is:\n",
      "[669]\ttraining's tweedie: 1.35\tvalid_1's tweedie: 1.38198\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35871\tvalid_1's tweedie: 1.38232\n",
      "[1000]\ttraining's tweedie: 1.33576\tvalid_1's tweedie: 1.38059\n",
      "Early stopping, best iteration is:\n",
      "[922]\ttraining's tweedie: 1.33843\tvalid_1's tweedie: 1.37926\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35872\tvalid_1's tweedie: 1.38417\n",
      "[1000]\ttraining's tweedie: 1.3366\tvalid_1's tweedie: 1.38193\n",
      "Early stopping, best iteration is:\n",
      "[945]\ttraining's tweedie: 1.33889\tvalid_1's tweedie: 1.38169\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35967\tvalid_1's tweedie: 1.38312\n",
      "[1000]\ttraining's tweedie: 1.33701\tvalid_1's tweedie: 1.38228\n",
      "Early stopping, best iteration is:\n",
      "[828]\ttraining's tweedie: 1.34347\tvalid_1's tweedie: 1.38126\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35933\tvalid_1's tweedie: 1.38374\n",
      "Early stopping, best iteration is:\n",
      "[708]\ttraining's tweedie: 1.3489\tvalid_1's tweedie: 1.38182\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's tweedie: 1.39188\tvalid_1's tweedie: 1.48679\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's tweedie: 1.40541\tvalid_1's tweedie: 1.485\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's tweedie: 1.41718\tvalid_1's tweedie: 1.48495\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's tweedie: 1.38204\tvalid_1's tweedie: 1.48265\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's tweedie: 1.40888\tvalid_1's tweedie: 1.4879\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's tweedie: 0.908034\tvalid_1's tweedie: 0.955801\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's tweedie: 0.880384\tvalid_1's tweedie: 0.954937\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's tweedie: 0.887558\tvalid_1's tweedie: 0.955108\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's tweedie: 0.89673\tvalid_1's tweedie: 0.963812\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's tweedie: 0.889261\tvalid_1's tweedie: 0.955121\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's cross_entropy: 0.358242\tvalid_1's cross_entropy: 0.510386\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's cross_entropy: 0.343119\tvalid_1's cross_entropy: 0.502554\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's cross_entropy: 0.38125\tvalid_1's cross_entropy: 0.510032\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's cross_entropy: 0.392922\tvalid_1's cross_entropy: 0.509073\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's cross_entropy: 0.375513\tvalid_1's cross_entropy: 0.50387\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35827\tvalid_1's tweedie: 1.39403\n",
      "[1000]\ttraining's tweedie: 1.33777\tvalid_1's tweedie: 1.39081\n",
      "Early stopping, best iteration is:\n",
      "[1055]\ttraining's tweedie: 1.33586\tvalid_1's tweedie: 1.3903\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.36041\tvalid_1's tweedie: 1.39525\n",
      "Early stopping, best iteration is:\n",
      "[766]\ttraining's tweedie: 1.34661\tvalid_1's tweedie: 1.39287\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35919\tvalid_1's tweedie: 1.39435\n",
      "Early stopping, best iteration is:\n",
      "[551]\ttraining's tweedie: 1.35638\tvalid_1's tweedie: 1.39361\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.36008\tvalid_1's tweedie: 1.39436\n",
      "[1000]\ttraining's tweedie: 1.33775\tvalid_1's tweedie: 1.39265\n",
      "Early stopping, best iteration is:\n",
      "[1005]\ttraining's tweedie: 1.33746\tvalid_1's tweedie: 1.39216\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35961\tvalid_1's tweedie: 1.39698\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's tweedie: 1.35691\tvalid_1's tweedie: 1.39546\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's tweedie: 1.4046\tvalid_1's tweedie: 1.43156\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's tweedie: 1.36455\tvalid_1's tweedie: 1.42932\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's tweedie: 1.40241\tvalid_1's tweedie: 1.43643\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's tweedie: 1.39507\tvalid_1's tweedie: 1.4316\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's tweedie: 1.39633\tvalid_1's tweedie: 1.42121\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's tweedie: 0.947\tvalid_1's tweedie: 0.982825\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's tweedie: 0.937829\tvalid_1's tweedie: 0.979681\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's tweedie: 0.958607\tvalid_1's tweedie: 0.984099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's tweedie: 0.950464\tvalid_1's tweedie: 0.98119\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's tweedie: 0.929126\tvalid_1's tweedie: 0.981462\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's cross_entropy: 0.360883\tvalid_1's cross_entropy: 0.469233\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\ttraining's cross_entropy: 0.328224\tvalid_1's cross_entropy: 0.469561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's cross_entropy: 0.344805\tvalid_1's cross_entropy: 0.468893\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's cross_entropy: 0.310652\tvalid_1's cross_entropy: 0.470496\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttraining's cross_entropy: 0.311199\tvalid_1's cross_entropy: 0.473672\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35445\tvalid_1's tweedie: 1.41161\n",
      "[1000]\ttraining's tweedie: 1.33283\tvalid_1's tweedie: 1.41057\n",
      "Early stopping, best iteration is:\n",
      "[864]\ttraining's tweedie: 1.33749\tvalid_1's tweedie: 1.40979\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35271\tvalid_1's tweedie: 1.41288\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's tweedie: 1.34414\tvalid_1's tweedie: 1.41163\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35426\tvalid_1's tweedie: 1.41169\n",
      "[1000]\ttraining's tweedie: 1.33179\tvalid_1's tweedie: 1.41018\n",
      "Early stopping, best iteration is:\n",
      "[908]\ttraining's tweedie: 1.33504\tvalid_1's tweedie: 1.40887\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.3533\tvalid_1's tweedie: 1.41175\n",
      "[1000]\ttraining's tweedie: 1.33268\tvalid_1's tweedie: 1.41043\n",
      "Early stopping, best iteration is:\n",
      "[832]\ttraining's tweedie: 1.33846\tvalid_1's tweedie: 1.40837\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's tweedie: 1.35463\tvalid_1's tweedie: 1.41155\n",
      "[1000]\ttraining's tweedie: 1.3331\tvalid_1's tweedie: 1.4099\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's tweedie: 1.34041\tvalid_1's tweedie: 1.40868\n"
     ]
    }
   ],
   "source": [
    "off_df, test_df2 = make_offdf(train_df, test_df, feature, param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523139</td>\n",
       "      <td>0.159720</td>\n",
       "      <td>-0.449663</td>\n",
       "      <td>-0.148184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121813</td>\n",
       "      <td>0.376737</td>\n",
       "      <td>-0.212941</td>\n",
       "      <td>-0.175626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.402073</td>\n",
       "      <td>-0.231881</td>\n",
       "      <td>0.590057</td>\n",
       "      <td>-0.109977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.132501</td>\n",
       "      <td>-0.179171</td>\n",
       "      <td>-0.104027</td>\n",
       "      <td>0.431776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    preds_1   preds_2   preds_3   preds_4\n",
       "1  0.523139  0.159720 -0.449663 -0.148184\n",
       "2  0.121813  0.376737 -0.212941 -0.175626\n",
       "3 -0.402073 -0.231881  0.590057 -0.109977\n",
       "4 -0.132501 -0.179171 -0.104027  0.431776"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    pd.get_dummies(off_df.jobflag)[[1,2,3,4]],\n",
    "    off_df[[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "], axis=1).corr().loc[[1,2,3,4], [ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>jobflag</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215403</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.136661</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>0.671400</td>\n",
       "      <td>0.038088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.129037</td>\n",
       "      <td>0.071106</td>\n",
       "      <td>0.503242</td>\n",
       "      <td>0.315325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155156</td>\n",
       "      <td>0.140290</td>\n",
       "      <td>0.497517</td>\n",
       "      <td>0.105454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.133939</td>\n",
       "      <td>0.071106</td>\n",
       "      <td>0.693871</td>\n",
       "      <td>0.197089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.140502</td>\n",
       "      <td>0.104009</td>\n",
       "      <td>0.554698</td>\n",
       "      <td>0.163313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil       abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.000000     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.000000     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.438039     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.000000     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.000000     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit    ...     window  within      work  workflow     write  jobflag  \\\n",
       "0       0.0    ...        0.0     0.0  0.000000       0.0  0.215403      2.0   \n",
       "1       0.0    ...        0.0     0.0  0.000000       0.0  0.000000      4.0   \n",
       "2       0.0    ...        0.0     0.0  0.249759       0.0  0.000000      1.0   \n",
       "3       0.0    ...        0.0     0.0  0.000000       0.0  0.000000      3.0   \n",
       "4       0.0    ...        0.0     0.0  0.210919       0.0  0.000000      3.0   \n",
       "\n",
       "    preds_1   preds_2   preds_3   preds_4  \n",
       "0  0.136661  0.072682  0.671400  0.038088  \n",
       "1  0.129037  0.071106  0.503242  0.315325  \n",
       "2  0.155156  0.140290  0.497517  0.105454  \n",
       "3  0.133939  0.071106  0.693871  0.197089  \n",
       "4  0.140502  0.104009  0.554698  0.163313  \n",
       "\n",
       "[5 rows x 543 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>within</th>\n",
       "      <th>work</th>\n",
       "      <th>workflow</th>\n",
       "      <th>write</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142556</td>\n",
       "      <td>0.173217</td>\n",
       "      <td>0.537398</td>\n",
       "      <td>0.152072</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0.116612</td>\n",
       "      <td>0.609883</td>\n",
       "      <td>0.159805</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143299</td>\n",
       "      <td>0.078915</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>0.184956</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828860</td>\n",
       "      <td>0.090625</td>\n",
       "      <td>0.098464</td>\n",
       "      <td>0.086267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>0.644705</td>\n",
       "      <td>0.557995</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil  abl  accept  access  accord  account  accur  accuraci  achiev  \\\n",
       "0   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4   0.0  0.0     0.0     0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   acquisit  ...    window  within      work  workflow  write   preds_1  \\\n",
       "0       0.0  ...       0.0     0.0  0.544329       0.0    0.0  0.142556   \n",
       "1       0.0  ...       0.0     0.0  0.000000       0.0    0.0  0.062688   \n",
       "2       0.0  ...       0.0     0.0  0.000000       0.0    0.0  0.143299   \n",
       "3       0.0  ...       0.0     0.0  0.000000       0.0    0.0  0.828860   \n",
       "4       0.0  ...       0.0     0.0  0.000000       0.0    0.0  0.098633   \n",
       "\n",
       "    preds_2   preds_3   preds_4  preds  \n",
       "0  0.173217  0.537398  0.152072      3  \n",
       "1  0.116612  0.609883  0.159805      3  \n",
       "2  0.078915  0.496267  0.184956      3  \n",
       "3  0.090625  0.098464  0.086267      1  \n",
       "4  0.025735  0.644705  0.557995      3  \n",
       "\n",
       "[5 rows x 543 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ef5dc2ab6a442bbf31f2eaf7465c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94394d4753254c70ab8d7f4a5534625b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9733f50a5af4be599b273ed0c947f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744aa5eaedbe4968ae0990083cc78364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cf320be67f41d48b5ac2771ea862ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "k = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "off_df_2=[]\n",
    "test_preds = np.zeros(shape=(len(test_df2),4))\n",
    "\n",
    "for trn, val in k.split(train_df, train_df.jobflag):\n",
    "    trn_df = off_df.iloc[trn,:]\n",
    "    val_df  =  off_df.iloc[val,:]\n",
    "    \n",
    "    min_value = trn_df.jobflag.value_counts().min()\n",
    "    \n",
    "    preds = np.zeros(shape=(len(val_df),4))\n",
    "    \n",
    "    for i in tqdm(range(80)):\n",
    "        tmp_trn_df = pd.concat(\n",
    "        [trn_df[trn_df.jobflag==1].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==2].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==3].sample(n=min_value, random_state=i),\n",
    "         trn_df[trn_df.jobflag==4].sample(n=min_value, random_state=i)], axis=0).reset_index(drop=True)\n",
    "        tmp_trn_X = tmp_trn_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']]\n",
    "        tmp_trn_y = tmp_trn_df['jobflag']\n",
    "        \n",
    "        \n",
    "        for penalty  in [ 'l2']:\n",
    "            for m in range(5):\n",
    "                logit = LogisticRegression(penalty=penalty, random_state=m)\n",
    "                logit.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #ridge_cls = RidgeClassifier()\n",
    "                    #ridge_cls.fit(tmp_trn_X, tmp_trn_y)\n",
    "\n",
    "                    #kncls = KNeighborsClassifier(n_neighbors=4)\n",
    "                    #kncls.fit(tmp_trn_X, tmp_trn_y)\n",
    "                preds += logit.predict_proba(val_df[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])\n",
    "                test_preds += logit.predict_proba(test_df2[feature+[ 'preds_1', 'preds_2', 'preds_3', 'preds_4']])\n",
    "                \n",
    "    val_df[f'preds'] = np.argmax(preds, axis=1)+1\n",
    "    off_df_2.append(val_df)\n",
    "\n",
    "test_df2[f'preds'] = np.argmax(test_preds, axis=1)+1\n",
    "off_df_2 = pd.concat(off_df_2, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5670600790506621\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>140</td>\n",
       "      <td>67</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>166</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "      <td>920</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>136</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  337  140   67   80\n",
       "1   74  166   68   40\n",
       "2   72   92  920  292\n",
       "3   59   20  136  368"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics.f1_score(off_df_2.jobflag, off_df_2.preds, average='macro'))\n",
    "plt.figure(figsize=(10,10))\n",
    "cnfn_matrix = pd.DataFrame(metrics.confusion_matrix(off_df_2.jobflag, off_df_2.preds))\n",
    "#cnfn_matrix.index = \n",
    "sns.heatmap(cnfn_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "cnfn_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    611\n",
       "4    558\n",
       "1    364\n",
       "2    210\n",
       "Name: preds, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df2.preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../submit_sample.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[1] = test_df2.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2931</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2933</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2935</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2936</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2937</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2938</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2939</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2940</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2941</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2942</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2943</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2946</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2948</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2949</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2950</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2951</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2952</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2953</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2954</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2955</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2956</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2957</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2959</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2960</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>4644</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>4645</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>4646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>4647</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>4648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>4649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>4650</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>4651</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>4652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>4653</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>4654</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>4655</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>4656</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>4657</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>4658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>4659</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>4660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>4661</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>4662</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>4663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>4664</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>4665</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>4666</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>4667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>4668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>4669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>4670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>4671</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>4672</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>4673</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1\n",
       "0     2931  2\n",
       "1     2932  3\n",
       "2     2933  3\n",
       "3     2934  1\n",
       "4     2935  4\n",
       "5     2936  2\n",
       "6     2937  4\n",
       "7     2938  3\n",
       "8     2939  3\n",
       "9     2940  3\n",
       "10    2941  2\n",
       "11    2942  3\n",
       "12    2943  3\n",
       "13    2944  3\n",
       "14    2945  1\n",
       "15    2946  4\n",
       "16    2947  3\n",
       "17    2948  3\n",
       "18    2949  3\n",
       "19    2950  3\n",
       "20    2951  4\n",
       "21    2952  3\n",
       "22    2953  3\n",
       "23    2954  3\n",
       "24    2955  4\n",
       "25    2956  2\n",
       "26    2957  3\n",
       "27    2958  3\n",
       "28    2959  3\n",
       "29    2960  3\n",
       "...    ... ..\n",
       "1713  4644  4\n",
       "1714  4645  4\n",
       "1715  4646  1\n",
       "1716  4647  2\n",
       "1717  4648  4\n",
       "1718  4649  1\n",
       "1719  4650  3\n",
       "1720  4651  4\n",
       "1721  4652  1\n",
       "1722  4653  4\n",
       "1723  4654  2\n",
       "1724  4655  3\n",
       "1725  4656  4\n",
       "1726  4657  3\n",
       "1727  4658  1\n",
       "1728  4659  3\n",
       "1729  4660  2\n",
       "1730  4661  4\n",
       "1731  4662  3\n",
       "1732  4663  1\n",
       "1733  4664  3\n",
       "1734  4665  4\n",
       "1735  4666  3\n",
       "1736  4667  1\n",
       "1737  4668  1\n",
       "1738  4669  1\n",
       "1739  4670  4\n",
       "1740  4671  4\n",
       "1741  4672  4\n",
       "1742  4673  3\n",
       "\n",
       "[1743 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('/Users/kanoumotoharu/Downloads/sub_12.csv',  index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10127369, 0.40086803, 0.27877044, 0.21908784],\n",
       "       [0.08530234, 0.28073404, 0.39763328, 0.23633033],\n",
       "       [0.17745063, 0.25154499, 0.33936384, 0.23164054],\n",
       "       ...,\n",
       "       [0.25766106, 0.2301475 , 0.22386374, 0.2883277 ],\n",
       "       [0.06947772, 0.0708203 , 0.41543539, 0.44426659],\n",
       "       [0.07184275, 0.12031271, 0.59142699, 0.21641754]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds/(80*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
